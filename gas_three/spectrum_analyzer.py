# test_known_mixture.py
# ä½¿ç”¨å·²çŸ¥æµ“åº¦çš„æ··åˆå…‰è°±æµ‹è¯•æ¨¡å‹æ£€æµ‹æ€§èƒ½

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.preprocessing import StandardScaler
from scipy.interpolate import interp1d
import os
from datetime import datetime


class MixtureConcentrationTester:
    def __init__(self):
        self.model = None
        self.scaler = None
        self.wavenumber_range = None
        self.model_ready = False
        self.gas_names = ['NO', 'NO2', 'SO2']

        # å·²çŸ¥çš„çœŸå®æµ“åº¦
        self.true_concentrations = {
            'NO': 0.2,  # 20% (2/10)
            'NO2': 0.4,  # 40% (4/10)
            'SO2': 0.4  # 40% (4/10)
        }

    def load_trained_model(self):
        """åŠ è½½å·²è®­ç»ƒçš„æ¨¡å‹"""
        try:
            print("ğŸ“Š åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹...")

            # åŠ è½½è®­ç»ƒæ•°æ®é‡æ–°è®­ç»ƒæ¨¡å‹ï¼ˆå¦‚æœæ²¡æœ‰ä¿å­˜çš„æ¨¡å‹ï¼‰
            X_train = pd.read_csv("X_dataset.csv")
            Y_train = pd.read_csv("Y_labels.csv")

            # è·å–æ³¢æ•°èŒƒå›´
            wavenumber_cols = [col for col in X_train.columns if 'cm-1' in col]
            self.wavenumber_range = [float(col.replace('cm-1', '')) for col in wavenumber_cols]
            self.wavenumber_range.sort()

            # æ•°æ®é¢„å¤„ç†
            self.scaler = StandardScaler()
            X_train_scaled = self.scaler.fit_transform(X_train.values)
            #å¯¹Xè¿›è¡Œæ ‡å‡†åŒ–å¤„ç†(æ¯ä¸ªç‰¹å¾å‡å»å‡å€¼åé™¤ä»¥æ ‡å‡†å·®)  ç›®çš„ï¼šæ¶ˆé™¤ä¸åŒæ³¢æ•°ç‚¹å¼ºåº¦é‡çº²å·®å¼‚ï¼Œä½¿æ‰€æœ‰ç‰¹å¾å¤„äºç›¸åŒå°ºåº¦

            # è®­ç»ƒæ¨¡å‹
            # è®­ç»ƒPLSæ¨¡å‹

            # n_components=5 è¡¨ç¤ºä½¿ç”¨5ä¸ªæ½œåœ¨å˜é‡(ä¸»æˆåˆ†)
            self.model = PLSRegression(n_components=5)
            # æŒ‡å®šæ½œåœ¨å˜é‡(ä¸»æˆåˆ†)æ•°é‡ä¸º5
            # PLSé€šè¿‡å¯»æ‰¾Xå’ŒYä¹‹é—´çš„æœ€å¤§åæ–¹å·®æ–¹å‘æ¥æ„å»ºæ½œåœ¨å˜é‡




            # X_train_scaled: æ ‡å‡†åŒ–åçš„å…‰è°±æ•°æ®çŸ©é˜µ (æ ·æœ¬æ•° Ã— æ³¢æ•°ç‚¹)
            # Y_train.values: æµ“åº¦æ ‡ç­¾çŸ©é˜µ (æ ·æœ¬æ•° Ã— æ°”ä½“ç§ç±»)
            self.model.fit(X_train_scaled, Y_train.values)
            """1. åˆå§‹åŒ–:
   X0 = X (æ ‡å‡†åŒ–åçš„å…‰è°±æ•°æ®)
   Y0 = Y (æµ“åº¦çŸ©é˜µ)
   k = 0 (è¿­ä»£æ¬¡æ•°)

2. ä¸»æˆåˆ†æå–(é‡å¤ç›´åˆ°æå–n_componentsä¸ªæˆåˆ†):
   a. è®¡ç®—æƒé‡å‘é‡w:
        w = X_k' * Y_k / ||X_k' * Y_k||
        (æœ€å¤§åŒ–Xå’ŒYä¹‹é—´çš„åæ–¹å·®)
   
   b. è®¡ç®—Xå¾—åˆ†å‘é‡t:
        t = X_k * w
        (Xåœ¨wæ–¹å‘ä¸Šçš„æŠ•å½±)
   
   c. è®¡ç®—Yæƒé‡å‘é‡c:
        c = Y_k' * t / (t' * t)
        (Yåœ¨tæ–¹å‘ä¸Šçš„æƒé‡)
   
   d. è®¡ç®—Yå¾—åˆ†å‘é‡u:
        u = Y_k * c
        (Yåœ¨cæ–¹å‘ä¸Šçš„æŠ•å½±)
   
   e. è®¡ç®—Xè½½è·å‘é‡p:
        p = X_k' * t / (t' * t)
        (Xä¸tçš„å…³ç³»)
   
   f. è®¡ç®—Yè½½è·å‘é‡q:
        q = Y_k' * u / (u' * u)
        (Yä¸uçš„å…³ç³»)
   
   g. æ›´æ–°æ®‹å·®çŸ©é˜µ:
        X_{k+1} = X_k - t * p'
        Y_{k+1} = Y_k - t * c'
        (å‡å»å½“å‰ä¸»æˆåˆ†è§£é‡Šçš„éƒ¨åˆ†)
   
   h. k = k + 1

3. æ„å»ºå›å½’ç³»æ•°çŸ©é˜µB:
        B = W(P'W)^{-1}C'
        (å…¶ä¸­Wæ˜¯æƒé‡çŸ©é˜µï¼ŒPæ˜¯Xè½½è·çŸ©é˜µï¼ŒCæ˜¯Yæƒé‡çŸ©é˜µ)"""



            self.model_ready = True
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"ğŸ“Š æ¨¡å‹æ”¯æŒæ³¢æ•°èŒƒå›´: {min(self.wavenumber_range):.0f} - {max(self.wavenumber_range):.0f} cmâ»Â¹")
            print(f"ğŸ“Š è®­ç»ƒæ•°æ®è§„æ¨¡: {X_train.shape[0]} æ ·æœ¬, {X_train.shape[1]} ç‰¹å¾")

            return True

        except FileNotFoundError as e:
            print(f"âŒ æ‰¾ä¸åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶: {e}")
            print("è¯·ç¡®ä¿ X_dataset.csv å’Œ Y_labels.csv å­˜åœ¨")
            return False
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False

    def load_test_spectrum(self, file_path):
        """åŠ è½½æµ‹è¯•å…‰è°±æ•°æ®"""
        try:
            print(f"\nğŸ“„ è¯»å–æµ‹è¯•å…‰è°±: {file_path}")

            if not os.path.exists(file_path):
                print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
                return None, None

            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(file_path)

            # æ£€æŸ¥åˆ—å
            if 'wavenumber' not in df.columns or 'intensity' not in df.columns:
                print(f"âŒ æ–‡ä»¶æ ¼å¼é”™è¯¯ï¼Œéœ€è¦ 'wavenumber' å’Œ 'intensity' åˆ—")
                print(f"å®é™…åˆ—å: {list(df.columns)}")
                return None, None

            # æå–æ•°æ®
            wavenumbers = df['wavenumber'].values
            intensities = df['intensity'].values

            # ç§»é™¤æ— æ•ˆæ•°æ®
            valid_mask = np.isfinite(wavenumbers) & np.isfinite(intensities)
            wavenumbers_clean = wavenumbers[valid_mask]
            intensities_clean = intensities[valid_mask]

            print(f"âœ… æˆåŠŸè¯»å–æµ‹è¯•å…‰è°±")
            print(f"ğŸ“Š æ•°æ®ç‚¹æ•°: {len(wavenumbers_clean)}")
            print(f"ğŸ“Š æ³¢æ•°èŒƒå›´: {wavenumbers_clean.min():.1f} - {wavenumbers_clean.max():.1f} cmâ»Â¹")
            print(f"ğŸ“Š å¼ºåº¦èŒƒå›´: {intensities_clean.min():.3e} - {intensities_clean.max():.3e}")

            return wavenumbers_clean, intensities_clean

        except Exception as e:
            print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
            return None, None

    def preprocess_test_spectrum(self, wavenumbers, intensities):
        """é¢„å¤„ç†æµ‹è¯•å…‰è°±åˆ°æ¨¡å‹è¾“å…¥æ ¼å¼"""
        if not self.model_ready:
            print("âŒ æ¨¡å‹æœªåŠ è½½")
            return None

        print(f"\nğŸ”§ é¢„å¤„ç†æµ‹è¯•å…‰è°±...")

        # æ£€æŸ¥æ³¢æ•°èŒƒå›´å…¼å®¹æ€§
        test_min, test_max = wavenumbers.min(), wavenumbers.max()
        model_min, model_max = min(self.wavenumber_range), max(self.wavenumber_range)

        print(f"   æµ‹è¯•å…‰è°±èŒƒå›´: {test_min:.1f} - {test_max:.1f} cmâ»Â¹")
        print(f"   æ¨¡å‹éœ€è¦èŒƒå›´: {model_min:.1f} - {model_max:.1f} cmâ»Â¹")

        # è®¡ç®—è¦†ç›–åº¦
        overlap_min = max(test_min, model_min)
        overlap_max = min(test_max, model_max)

        if overlap_min >= overlap_max:
            print("âŒ æµ‹è¯•å…‰è°±ä¸æ¨¡å‹æ³¢æ•°èŒƒå›´ä¸åŒ¹é…")
            return None

        coverage = (overlap_max - overlap_min) / (model_max - model_min)
        print(f"   æ³¢æ•°è¦†ç›–åº¦: {coverage:.1%}")

        if coverage < 0.8:
            print("âš ï¸ è­¦å‘Š: æ³¢æ•°è¦†ç›–åº¦è¾ƒä½ï¼Œé¢„æµ‹å¯èƒ½ä¸å‡†ç¡®")

        # æ’å€¼åˆ°æ¨¡å‹æ³¢æ•°ç½‘æ ¼
        try:
            interp_func = interp1d(wavenumbers, intensities,
                                   kind='linear', bounds_error=False, fill_value=0)

            model_spectrum = interp_func(self.wavenumber_range)

            # æ£€æŸ¥æ’å€¼ç»“æœ
            valid_points = np.sum(model_spectrum != 0)
            total_points = len(model_spectrum)

            print(f"   æ’å€¼ç»“æœ: {valid_points}/{total_points} æœ‰æ•ˆç‚¹ ({valid_points / total_points:.1%})")

            return model_spectrum.reshape(1, -1)

        except Exception as e:
            print(f"âŒ å…‰è°±é¢„å¤„ç†å¤±è´¥: {e}")
            return None

    def predict_concentrations(self, spectrum_data):
        """é¢„æµ‹æ°”ä½“æµ“åº¦"""
        if not self.model_ready or spectrum_data is None:
            return None

        try:
            print(f"\nğŸ” è¿›è¡Œæµ“åº¦é¢„æµ‹...")

            # æ ‡å‡†åŒ–è¾“å…¥æ•°æ®  æ ‡å‡†åŒ–è¾“å…¥æ•°æ® (ä½¿ç”¨è®­ç»ƒæ—¶çš„scaler)
            spectrum_scaled = self.scaler.transform(spectrum_data)

            # é¢„æµ‹æµ“åº¦
            raw_predictions = self.model.predict(spectrum_scaled)[0]

            print(f"   åŸå§‹é¢„æµ‹å€¼: {raw_predictions}")

            # å¤„ç†é¢„æµ‹ç»“æœ
            # ç¡®ä¿éè´Ÿ
            predictions_positive = np.maximum(raw_predictions, 0)

            # å½’ä¸€åŒ–åˆ°æ€»å’Œä¸º1
            #"å½’ä¸€åŒ–åˆ°æ€»å’Œä¸º1"æ˜¯æŒ‡å°†é¢„æµ‹å‡ºçš„å„ä¸ªæ°”ä½“æµ“åº¦å€¼è¿›è¡Œè°ƒæ•´ï¼Œä½¿å¾—æ‰€æœ‰æ°”ä½“çš„æµ“åº¦é¢„æµ‹å€¼ä¹‹å’Œç­‰äº1ï¼ˆå³100%ï¼‰ã€‚
            # è¿™æ ·åšçš„ç›®çš„æ˜¯å°†é¢„æµ‹ç»“æœè¡¨ç¤ºä¸ºå„æ°”ä½“åœ¨æ··åˆç‰©ä¸­æ‰€å çš„æ¯”ä¾‹ã€‚
            total = np.sum(predictions_positive)
            if total > 0:
                predictions_normalized = predictions_positive / total
            else:
                # å¦‚æœæ‰€æœ‰é¢„æµ‹éƒ½æ˜¯0ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ
                predictions_normalized = np.array([1 / 3, 1 / 3, 1 / 3])
                print("âš ï¸ æ‰€æœ‰é¢„æµ‹å€¼ä¸º0ï¼Œä½¿ç”¨å‡åŒ€åˆ†å¸ƒ")

            print(f"   å½’ä¸€åŒ–é¢„æµ‹: {predictions_normalized}")

            # ç»„ç»‡ç»“æœ
            predicted_concentrations = {}
            for i, gas in enumerate(self.gas_names):
                predicted_concentrations[gas] = float(predictions_normalized[i])

            return predicted_concentrations

        except Exception as e:
            print(f"âŒ æµ“åº¦é¢„æµ‹å¤±è´¥: {e}")
            return None

    def calculate_errors(self, predicted_concentrations):
        """è®¡ç®—é¢„æµ‹è¯¯å·®"""
        print(f"\nğŸ“Š è®¡ç®—é¢„æµ‹è¯¯å·®...")

        errors = {}
        absolute_errors = []
        relative_errors = []

        print(f"{'æ°”ä½“':>6} {'çœŸå®å€¼':>8} {'é¢„æµ‹å€¼':>8} {'ç»å¯¹è¯¯å·®':>8} {'ç›¸å¯¹è¯¯å·®':>8}")
        print("-" * 50)
        # éå†æ¯ç§æ°”ä½“
        for gas in self.gas_names:
            # è·å–çœŸå®å€¼å’Œé¢„æµ‹å€¼
            true_val = self.true_concentrations[gas]
            pred_val = predicted_concentrations[gas]
            # è®¡ç®—ç»å¯¹è¯¯å·® = |é¢„æµ‹å€¼ - çœŸå®å€¼|
            abs_error = abs(pred_val - true_val)
            # è®¡ç®—ç›¸å¯¹è¯¯å·® = (|é¢„æµ‹å€¼ - çœŸå®å€¼| / çœŸå®å€¼) * 100%
            # é¿å…é™¤ä»¥é›¶é”™è¯¯ï¼ˆçœŸå®å€¼>0æ—¶è®¡ç®—ï¼‰
            rel_error = (abs_error / true_val) * 100 if true_val > 0 else 0

            errors[gas] = {
                'true': true_val,
                'predicted': pred_val,
                'absolute_error': abs_error,
                'relative_error': rel_error
            }
            # æ”¶é›†è¯¯å·®ç”¨äºæ•´ä½“ç»Ÿè®¡
            absolute_errors.append(abs_error)
            relative_errors.append(rel_error)

            print(f"{gas:>6} {true_val:>8.3f} {pred_val:>8.3f} {abs_error:>8.3f} {rel_error:>7.1f}%")

        # æ€»ä½“è¯¯å·®ç»Ÿè®¡
        mean_abs_error = np.mean(absolute_errors)
        mean_rel_error = np.mean(relative_errors)
        max_rel_error = np.max(relative_errors)

        print("-" * 50)
        print(f"{'å¹³å‡':>6} {'':>8} {'':>8} {mean_abs_error:>8.3f} {mean_rel_error:>7.1f}%")
        print(f"æœ€å¤§ç›¸å¯¹è¯¯å·®: {max_rel_error:.1f}%")

        # æ€§èƒ½è¯„ä¼°
        if mean_rel_error < 5:
            performance = "ğŸŒŸ ä¼˜ç§€"
        elif mean_rel_error < 10:
            performance = "âœ… è‰¯å¥½"
        elif mean_rel_error < 20:
            performance = "âš ï¸ ä¸€èˆ¬"
        else:
            performance = "âŒ è¾ƒå·®"

        print(f"\nğŸ¯ æ¨¡å‹æ€§èƒ½è¯„ä¼°: {performance} (å¹³å‡ç›¸å¯¹è¯¯å·®: {mean_rel_error:.1f}%)")

        return errors, mean_abs_error, mean_rel_error

    def visualize_results(self, wavenumbers, intensities, predicted_concentrations, errors):
        """å¯è§†åŒ–æµ‹è¯•ç»“æœ"""
        try:
            print(f"\nğŸ“Š ç”Ÿæˆç»“æœå¯è§†åŒ–...")

            fig, axes = plt.subplots(2, 2, figsize=(15, 12))

            # 1. æµ‹è¯•å…‰è°±
            axes[0, 0].plot(wavenumbers, intensities, 'blue', linewidth=1.5, alpha=0.8)
            axes[0, 0].set_title('Test Spectrum (Known 2:4:4 Mixture)', fontweight='bold')
            axes[0, 0].set_xlabel('Wavenumber (cmâ»Â¹)')
            axes[0, 0].set_ylabel('Intensity')
            axes[0, 0].grid(True, alpha=0.3)
            axes[0, 0].ticklabel_format(style='scientific', axis='y', scilimits=(0, 0))

            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
            max_intensity = intensities.max()
            mean_intensity = intensities.mean()
            axes[0, 0].text(0.02, 0.98, f'Max: {max_intensity:.2e}\nMean: {mean_intensity:.2e}',
                            transform=axes[0, 0].transAxes,
                            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue"),
                            verticalalignment='top', fontsize=9)

            # 2. çœŸå®å€¼vsé¢„æµ‹å€¼å¯¹æ¯”
            gas_names = list(predicted_concentrations.keys())
            true_values = [self.true_concentrations[gas] for gas in gas_names]
            pred_values = [predicted_concentrations[gas] for gas in gas_names]

            x = np.arange(len(gas_names))
            width = 0.35

            bars1 = axes[0, 1].bar(x - width / 2, true_values, width,
                                   label='True', color='green', alpha=0.7)
            bars2 = axes[0, 1].bar(x + width / 2, pred_values, width,
                                   label='Predicted', color='orange', alpha=0.7)

            axes[0, 1].set_title('True vs Predicted Concentrations', fontweight='bold')
            axes[0, 1].set_xlabel('Gas Type')
            axes[0, 1].set_ylabel('Concentration')
            axes[0, 1].set_xticks(x)
            axes[0, 1].set_xticklabels(gas_names)
            axes[0, 1].legend()
            axes[0, 1].grid(True, alpha=0.3)

            # æ·»åŠ æ•°å€¼æ ‡ç­¾
            for bars in [bars1, bars2]:
                for bar in bars:
                    height = bar.get_height()
                    axes[0, 1].text(bar.get_x() + bar.get_width() / 2., height,
                                    f'{height:.3f}', ha='center', va='bottom', fontsize=9)

            # 3. è¯¯å·®åˆ†æ
            rel_errors = [errors[gas]['relative_error'] for gas in gas_names]
            colors = ['red', 'blue', 'green']

            bars = axes[1, 0].bar(gas_names, rel_errors, color=colors, alpha=0.7)
            axes[1, 0].set_title('Relative Error by Gas', fontweight='bold')
            axes[1, 0].set_xlabel('Gas Type')
            axes[1, 0].set_ylabel('Relative Error (%)')
            axes[1, 0].grid(True, alpha=0.3)

            # æ·»åŠ è¯¯å·®æ ‡ç­¾
            for bar, error in zip(bars, rel_errors):
                height = bar.get_height()
                axes[1, 0].text(bar.get_x() + bar.get_width() / 2., height,
                                f'{error:.1f}%', ha='center', va='bottom', fontsize=9)

            # 4. æ•£ç‚¹å›¾ (çœŸå®å€¼ vs é¢„æµ‹å€¼)
            axes[1, 1].scatter(true_values, pred_values,
                               c=colors, s=100, alpha=0.7, edgecolors='black')

            # æ·»åŠ å®Œç¾é¢„æµ‹çº¿
            min_val = min(min(true_values), min(pred_values))
            max_val = max(max(true_values), max(pred_values))
            axes[1, 1].plot([min_val, max_val], [min_val, max_val],
                            'k--', alpha=0.5, linewidth=2, label='Perfect Prediction')

            # æ ‡æ³¨æ°”ä½“åç§°
            for i, gas in enumerate(gas_names):
                axes[1, 1].annotate(gas, (true_values[i], pred_values[i]),
                                    xytext=(5, 5), textcoords='offset points',
                                    fontsize=10, fontweight='bold')

            axes[1, 1].set_title('True vs Predicted (Scatter Plot)', fontweight='bold')
            axes[1, 1].set_xlabel('True Concentration')
            axes[1, 1].set_ylabel('Predicted Concentration')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
            axes[1, 1].set_aspect('equal', adjustable='box')

            # æ·»åŠ RÂ²ä¿¡æ¯
            from sklearn.metrics import r2_score
            r2 = r2_score(true_values, pred_values)
            axes[1, 1].text(0.05, 0.95, f'RÂ² = {r2:.4f}',
                            transform=axes[1, 1].transAxes,
                            bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow"),
                            verticalalignment='top', fontsize=10)

            plt.suptitle('Gas Concentration Detection Test Results\n'
                         'Known Mixture: NO:NO2:SO2 = 2:4:4 (20%:40%:40%)',
                         fontsize=14, fontweight='bold')

            plt.tight_layout()

            # ä¿å­˜å›¾è¡¨
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            plot_filename = f'concentration_test_results_{timestamp}.png'
            plt.savefig(plot_filename, dpi=300, bbox_inches='tight')
            print(f"ğŸ“Š ç»“æœå›¾è¡¨å·²ä¿å­˜: {plot_filename}")

            plt.show()

        except Exception as e:
            print(f"âš ï¸ å¯è§†åŒ–å¤±è´¥: {e}")

    def test_mixture_concentration(self, test_file_path):
        """å®Œæ•´çš„æ··åˆç‰©æµ“åº¦æµ‹è¯•æµç¨‹"""
        print("ğŸ”¬ å·²çŸ¥æ··åˆå…‰è°±çš„æµ“åº¦æ£€æµ‹æµ‹è¯•")
        print("=" * 60)
        print(f"æµ‹è¯•æ–‡ä»¶: {test_file_path}")
        print(f"å·²çŸ¥çœŸå®æµ“åº¦: NO={self.true_concentrations['NO']:.1%}, "
              f"NO2={self.true_concentrations['NO2']:.1%}, "
              f"SO2={self.true_concentrations['SO2']:.1%}")
        print("=" * 60)

        # 1. åŠ è½½æ¨¡å‹
        if not self.load_trained_model():
            return None

        # 2. è¯»å–æµ‹è¯•å…‰è°±
        wavenumbers, intensities = self.load_test_spectrum(test_file_path)
        if wavenumbers is None:
            return None

        # 3. é¢„å¤„ç†å…‰è°±
        spectrum_data = self.preprocess_test_spectrum(wavenumbers, intensities)
        if spectrum_data is None:
            return None

        # 4. é¢„æµ‹æµ“åº¦
        predicted_concentrations = self.predict_concentrations(spectrum_data)
        if predicted_concentrations is None:
            return None

        # 5. è®¡ç®—è¯¯å·®
        errors, mean_abs_error, mean_rel_error = self.calculate_errors(predicted_concentrations)

        # 6. å¯è§†åŒ–ç»“æœ
        self.visualize_results(wavenumbers, intensities, predicted_concentrations, errors)

        # 7. ä¿å­˜è¯¦ç»†ç»“æœ
        self.save_test_results(predicted_concentrations, errors, mean_abs_error, mean_rel_error)

        return {
            'predicted_concentrations': predicted_concentrations,
            'errors': errors,
            'mean_absolute_error': mean_abs_error,
            'mean_relative_error': mean_rel_error
        }

    def save_test_results(self, predicted_concentrations, errors, mean_abs_error, mean_rel_error):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

            # åˆ›å»ºç»“æœDataFrame
            results_data = []
            for gas in self.gas_names:
                results_data.append({
                    'Gas': gas,
                    'True_Concentration': self.true_concentrations[gas],
                    'Predicted_Concentration': predicted_concentrations[gas],
                    'Absolute_Error': errors[gas]['absolute_error'],
                    'Relative_Error_Percent': errors[gas]['relative_error']
                })

            results_df = pd.DataFrame(results_data)

            # ä¿å­˜CSV
            csv_filename = f'concentration_test_results_{timestamp}.csv'
            results_df.to_csv(csv_filename, index=False)

            # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
            report_filename = f'test_report_{timestamp}.txt'
            with open(report_filename, 'w', encoding='utf-8') as f:
                f.write("æ°”ä½“æµ“åº¦æ£€æµ‹æµ‹è¯•æŠ¥å‘Š\n")
                f.write("=" * 50 + "\n")
                f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å·²çŸ¥æ··åˆæ¯”ä¾‹: NO:NO2:SO2 = 2:4:4\n\n")

                f.write("è¯¦ç»†ç»“æœ:\n")
                f.write("-" * 30 + "\n")
                for gas in self.gas_names:
                    f.write(f"{gas}:\n")
                    f.write(f"  çœŸå®æµ“åº¦: {self.true_concentrations[gas]:.3f}\n")
                    f.write(f"  é¢„æµ‹æµ“åº¦: {predicted_concentrations[gas]:.3f}\n")
                    f.write(f"  ç»å¯¹è¯¯å·®: {errors[gas]['absolute_error']:.3f}\n")
                    f.write(f"  ç›¸å¯¹è¯¯å·®: {errors[gas]['relative_error']:.1f}%\n\n")

                f.write(f"æ€»ä½“æ€§èƒ½:\n")
                f.write(f"  å¹³å‡ç»å¯¹è¯¯å·®: {mean_abs_error:.3f}\n")
                f.write(f"  å¹³å‡ç›¸å¯¹è¯¯å·®: {mean_rel_error:.1f}%\n")

            print(f"ğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜:")
            print(f"   ğŸ“„ {csv_filename}")
            print(f"   ğŸ“‹ {report_filename}")

        except Exception as e:
            print(f"âš ï¸ ä¿å­˜ç»“æœå¤±è´¥: {e}")


# ä¸»å‡½æ•°
def test_known_mixture():
    """æµ‹è¯•å·²çŸ¥æµ“åº¦çš„æ··åˆå…‰è°±"""
    tester = MixtureConcentrationTester()

    # ä½ çš„æµ‹è¯•æ–‡ä»¶è·¯å¾„
    test_file = r"E:\generate_mixture\gas_three\test\mixed_spectrum_244_noisy_20250710_152143.csv"

    # è¿è¡Œæµ‹è¯•
    results = tester.test_mixture_concentration(test_file)

    if results:
        print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
        print(f"ğŸ“Š ç»“æœæ‘˜è¦:")
        print(f"   å¹³å‡ç›¸å¯¹è¯¯å·®: {results['mean_relative_error']:.1f}%")

        if results['mean_relative_error'] < 5:
            print(f"   ğŸŒŸ æ¨¡å‹æ€§èƒ½ä¼˜ç§€ï¼")
        elif results['mean_relative_error'] < 10:
            print(f"   âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½")
        else:
            print(f"   âš ï¸ æ¨¡å‹æ€§èƒ½æœ‰å¾…æå‡")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥")


if __name__ == "__main__":
    test_known_mixture()