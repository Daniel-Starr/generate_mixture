# detect_spectrum.py
# ä¸“é—¨ç”¨äºŽæ£€æµ‹å…‰è°±æ•°æ®ä¸­çš„æ°”ä½“æµ“åº¦

import pandas as pd
import numpy as np
import joblib
import os
from scipy.interpolate import interp1d
import matplotlib.pyplot as plt

class SpectrumDetector:
    """å…‰è°±æ£€æµ‹å™¨ - æ”¯æŒå¤šç§æ¨¡åž‹"""
    
    def __init__(self):
        self.models = {}
        self.scalers = {}
        
    def load_enhanced_model(self):
        """åŠ è½½Enhancedæ¨¡åž‹"""
        try:
            model_path = "data/models/enhanced_pls_model.pkl"
            scaler_X_path = "data/models/scaler_X.pkl"
            scaler_Y_path = "data/models/scaler_Y.pkl"
            
            if all(os.path.exists(p) for p in [model_path, scaler_X_path, scaler_Y_path]):
                self.models['enhanced'] = {
                    'model': joblib.load(model_path),
                    'scaler_X': joblib.load(scaler_X_path),
                    'scaler_Y': joblib.load(scaler_Y_path)
                }
                print("âœ“ Enhanced model loaded")
                return True
            else:
                print("âœ— Enhanced model files not found")
                return False
        except Exception as e:
            print(f"âœ— Enhanced model loading failed: {e}")
            return False
    
    def load_standard_model(self):
        """åŠ è½½Standardæ¨¡åž‹"""
        try:
            model_path = "data/models/standard/standard_pls_model.pkl"
            scaler_X_path = "data/models/standard/standard_scaler_X.pkl"
            scaler_Y_path = "data/models/standard/standard_scaler_Y.pkl"
            
            if all(os.path.exists(p) for p in [model_path, scaler_X_path, scaler_Y_path]):
                self.models['standard'] = {
                    'model': joblib.load(model_path),
                    'scaler_X': joblib.load(scaler_X_path),
                    'scaler_Y': joblib.load(scaler_Y_path)
                }
                print("âœ“ Standard model loaded")
                return True
            else:
                print("âœ— Standard model files not found")
                return False
        except Exception as e:
            print(f"âœ— Standard model loading failed: {e}")
            return False
    
    def load_reference_wavenumbers(self):
        """åŠ è½½å‚è€ƒæ³¢æ•°è½´"""
        # å°è¯•ä»Žä¸åŒä½ç½®åŠ è½½å‚è€ƒæ³¢æ•°
        possible_files = [
            "data/processed/interpolated_spectra.csv",
            "data/processed/standard_interpolated_spectra.csv"
        ]
        
        for file_path in possible_files:
            if os.path.exists(file_path):
                ref_df = pd.read_csv(file_path)
                self.reference_wavenumbers = ref_df['wavenumber'].values
                print(f"âœ“ Reference wavenumbers loaded from {file_path}")
                print(f"  Range: {self.reference_wavenumbers.min():.1f} - {self.reference_wavenumbers.max():.1f} cmâ»Â¹")
                return True
        
        print("âœ— Reference wavenumbers not found")
        return False
    
    def preprocess_spectrum(self, file_path):
        """é¢„å¤„ç†å…‰è°±æ•°æ®"""
        print(f"Loading spectrum from: {file_path}")
        
        # è¯»å–å…‰è°±æ•°æ®
        df = pd.read_csv(file_path)
        
        # æ£€æŸ¥æ•°æ®æ ¼å¼
        if 'wavenumber' in df.columns and 'intensity' in df.columns:
            wavenumbers = df['wavenumber'].values
            intensities = df['intensity'].values
        elif len(df.columns) >= 2:
            # å‡è®¾ç¬¬ä¸€åˆ—æ˜¯æ³¢æ•°ï¼Œç¬¬äºŒåˆ—æ˜¯å¼ºåº¦
            wavenumbers = df.iloc[:, 0].values
            intensities = df.iloc[:, 1].values
        else:
            raise ValueError("Cannot identify wavenumber and intensity columns")
        
        print(f"  Original data: {len(wavenumbers)} points")
        print(f"  Wavenumber range: {wavenumbers.min():.1f} - {wavenumbers.max():.1f} cmâ»Â¹")
        print(f"  Intensity range: {intensities.min():.2e} - {intensities.max():.2e}")
        
        # æ’å€¼åˆ°å‚è€ƒæ³¢æ•°è½´
        if hasattr(self, 'reference_wavenumbers'):
            print("  Interpolating to reference wavenumber axis...")
            
            # æ‰¾åˆ°é‡å èŒƒå›´
            overlap_min = max(wavenumbers.min(), self.reference_wavenumbers.min())
            overlap_max = min(wavenumbers.max(), self.reference_wavenumbers.max())
            
            if overlap_min >= overlap_max:
                raise ValueError("No overlap with reference wavenumber range")
            
            print(f"  Overlap range: {overlap_min:.1f} - {overlap_max:.1f} cmâ»Â¹")
            
            # é™åˆ¶å‚è€ƒæ³¢æ•°åˆ°é‡å èŒƒå›´
            ref_mask = (self.reference_wavenumbers >= overlap_min) & (self.reference_wavenumbers <= overlap_max)
            ref_wavenumbers_clipped = self.reference_wavenumbers[ref_mask]
            
            # æ’å€¼
            interpolator = interp1d(wavenumbers, intensities, 
                                  kind='linear', bounds_error=False, fill_value=0)
            interpolated_intensities = interpolator(ref_wavenumbers_clipped)
            
            print(f"  Interpolated data: {len(interpolated_intensities)} points")
            
            return interpolated_intensities
        else:
            # ç›´æŽ¥ä½¿ç”¨åŽŸå§‹æ•°æ®
            print("  Using original data (no reference axis)")
            return intensities
    
    def predict_with_model(self, spectral_data, model_name):
        """ä½¿ç”¨æŒ‡å®šæ¨¡åž‹è¿›è¡Œé¢„æµ‹"""
        if model_name not in self.models:
            raise ValueError(f"Model {model_name} not loaded")
        
        model_info = self.models[model_name]
        model = model_info['model']
        scaler_X = model_info['scaler_X']
        scaler_Y = model_info['scaler_Y']
        
        # ç¡®ä¿æ•°æ®å½¢çŠ¶æ­£ç¡®
        if spectral_data.ndim == 1:
            spectral_data = spectral_data.reshape(1, -1)
        
        # æ£€æŸ¥ç‰¹å¾ç»´åº¦
        expected_features = model.n_features_in_
        actual_features = spectral_data.shape[1]
        
        if actual_features != expected_features:
            print(f"  Adjusting feature dimensions: {actual_features} â†’ {expected_features}")
            
            if actual_features > expected_features:
                spectral_data = spectral_data[:, :expected_features]
            else:
                padding = np.zeros((spectral_data.shape[0], expected_features - actual_features))
                spectral_data = np.hstack([spectral_data, padding])
        
        # æ ‡å‡†åŒ–å’Œé¢„æµ‹
        X_scaled = scaler_X.transform(spectral_data)
        Y_pred_scaled = model.predict(X_scaled)
        Y_pred = scaler_Y.inverse_transform(Y_pred_scaled)
        
        # ç¡®ä¿æµ“åº¦ä¸ºæ­£ä¸”å’Œä¸º1
        Y_pred = np.maximum(Y_pred, 0)
        Y_pred = Y_pred / Y_pred.sum(axis=1, keepdims=True)
        
        return Y_pred[0]  # è¿”å›žå•ä¸ªé¢„æµ‹ç»“æžœ
    
    def detect_gases(self, file_path):
        """æ£€æµ‹å…‰è°±ä¸­çš„æ°”ä½“æµ“åº¦"""
        print("="*60)
        print("GAS CONCENTRATION DETECTION")
        print("="*60)
        print(f"Target file: {file_path}")
        print()
        
        # é¢„å¤„ç†å…‰è°±
        try:
            spectral_data = self.preprocess_spectrum(file_path)
        except Exception as e:
            print(f"ERROR in preprocessing: {e}")
            return None
        
        print()
        print("DETECTION RESULTS:")
        print("="*40)
        
        results = {}
        gas_names = ['NO', 'NO2', 'SO2']
        
        # ä½¿ç”¨æ‰€æœ‰å¯ç”¨æ¨¡åž‹è¿›è¡Œé¢„æµ‹
        for model_name in self.models.keys():
            try:
                print(f"\n{model_name.upper()} Model Prediction:")
                prediction = self.predict_with_model(spectral_data, model_name)
                
                results[model_name] = prediction
                
                for i, gas in enumerate(gas_names):
                    conc = prediction[i]
                    print(f"  {gas}: {conc:.4f} ({conc*100:.1f}%)")
                
                total = prediction.sum()
                print(f"  Total: {total:.4f}")
                
            except Exception as e:
                print(f"  ERROR with {model_name} model: {e}")
        
        # å¦‚æžœæœ‰å¤šä¸ªæ¨¡åž‹ï¼Œè®¡ç®—å¹³å‡å€¼
        if len(results) > 1:
            print(f"\nAVERAGE Prediction (from {len(results)} models):")
            avg_prediction = np.mean(list(results.values()), axis=0)
            
            for i, gas in enumerate(gas_names):
                conc = avg_prediction[i]
                print(f"  {gas}: {conc:.4f} ({conc*100:.1f}%)")
        
        # ä¿å­˜ç»“æžœ
        self.save_detection_results(file_path, results)
        
        return results
    
    def save_detection_results(self, input_file, results):
        """ä¿å­˜æ£€æµ‹ç»“æžœ"""
        os.makedirs("data/results/detection", exist_ok=True)
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        input_filename = os.path.basename(input_file).replace('.csv', '')
        output_file = f"data/results/detection/{input_filename}_detection_results.csv"
        
        # åˆ›å»ºç»“æžœDataFrame
        gas_names = ['NO', 'NO2', 'SO2']
        result_data = []
        
        for model_name, prediction in results.items():
            row = {'Model': model_name}
            for i, gas in enumerate(gas_names):
                row[f'{gas}_concentration'] = prediction[i]
                row[f'{gas}_percentage'] = prediction[i] * 100
            result_data.append(row)
        
        # å¦‚æžœæœ‰å¤šä¸ªæ¨¡åž‹ï¼Œæ·»åŠ å¹³å‡å€¼
        if len(results) > 1:
            avg_prediction = np.mean(list(results.values()), axis=0)
            row = {'Model': 'AVERAGE'}
            for i, gas in enumerate(gas_names):
                row[f'{gas}_concentration'] = avg_prediction[i]
                row[f'{gas}_percentage'] = avg_prediction[i] * 100
            result_data.append(row)
        
        results_df = pd.DataFrame(result_data)
        results_df.to_csv(output_file, index=False)
        
        print(f"\nðŸ“„ Results saved to: {output_file}")

def detect_spectrum_file(file_path):
    """æ£€æµ‹å•ä¸ªå…‰è°±æ–‡ä»¶"""
    detector = SpectrumDetector()
    
    # åŠ è½½æ‰€æœ‰å¯ç”¨æ¨¡åž‹
    print("Loading available models...")
    detector.load_enhanced_model()
    detector.load_standard_model()
    
    if not detector.models:
        print("ERROR: No models available. Please build models first.")
        return None
    
    # åŠ è½½å‚è€ƒæ³¢æ•°
    detector.load_reference_wavenumbers()
    
    # æ‰§è¡Œæ£€æµ‹
    results = detector.detect_gases(file_path)
    
    return results

if __name__ == "__main__":
    import sys
    
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
    else:
        # é»˜è®¤ä½¿ç”¨æ‚¨æŒ‡å®šçš„æ–‡ä»¶
        file_path = "E:/generate_mixture/gas_three/test/mixed_spectrum_244_clean_20250725_151622.csv"
    
    print("SPECTRUM DETECTION TOOL")
    print("="*40)
    print(f"Analyzing: {file_path}")
    print()
    
    if os.path.exists(file_path):
        results = detect_spectrum_file(file_path)
        
        if results:
            print("\n" + "="*60)
            print("DETECTION COMPLETED SUCCESSFULLY!")
            print("="*60)
        else:
            print("\n" + "="*60)
            print("DETECTION FAILED!")
            print("="*60)
    else:
        print(f"ERROR: File not found - {file_path}")