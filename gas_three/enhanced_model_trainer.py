# enhanced_model_trainer.py
# å¢å¼ºæ¨¡å‹è®­ç»ƒå™¨ - åŒ…å«ä¸¥æ ¼çš„æ¨¡å‹è¯„ä¼°å’Œäº¤å‰éªŒè¯

import pandas as pd
import numpy as np
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score, KFold, GroupKFold
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
import json
import os
from typing import Dict, List, Tuple, Optional
import warnings
warnings.filterwarnings('ignore')

# è§£å†³ä¸­æ–‡å­—ä½“æ˜¾ç¤ºé—®é¢˜
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Arial Unicode MS', 'Microsoft YaHei']
plt.rcParams['axes.unicode_minus'] = False

class EnhancedModelTrainer:
    """
    å¢å¼ºç‰ˆæ¨¡å‹è®­ç»ƒå™¨ï¼Œæä¾›ï¼š
    1. ä¸¥æ ¼çš„äº¤å‰éªŒè¯
    2. å¤šç§è¯„ä¼°æŒ‡æ ‡
    3. æ¨¡å‹å¤æ‚åº¦åˆ†æ
    4. é²æ£’æ€§æµ‹è¯•
    """
    
    def __init__(self, max_components: int = 20, cv_folds: int = 5, random_state: int = 42):
        self.max_components = max_components
        self.cv_folds = cv_folds
        self.random_state = random_state
        self.models = {}
        self.results = {}
        self.scaler_X = StandardScaler()
        self.scaler_Y = StandardScaler()
        
    def train_with_cross_validation(self, X_train: pd.DataFrame, Y_train: pd.DataFrame,
                                  X_val: pd.DataFrame, Y_val: pd.DataFrame,
                                  use_scaling: bool = True) -> Dict:
        """
        ä½¿ç”¨äº¤å‰éªŒè¯è®­ç»ƒæ¨¡å‹å¹¶é€‰æ‹©æœ€ä¼˜å‚æ•°
        """
        print("ğŸš€ å¼€å§‹å¢å¼ºæ¨¡å‹è®­ç»ƒä¸éªŒè¯...")
        
        # æ•°æ®é¢„å¤„ç†
        if use_scaling:
            X_train_scaled = self.scaler_X.fit_transform(X_train)
            X_val_scaled = self.scaler_X.transform(X_val)
            Y_train_scaled = self.scaler_Y.fit_transform(Y_train)
            Y_val_scaled = self.scaler_Y.transform(Y_val)
        else:
            X_train_scaled = X_train.values
            X_val_scaled = X_val.values
            Y_train_scaled = Y_train.values
            Y_val_scaled = Y_val.values
        
        print(f"   ğŸ“Š è®­ç»ƒæ•°æ®: {X_train_scaled.shape}, éªŒè¯æ•°æ®: {X_val_scaled.shape}")
        
        # 1. äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜ç»„ä»¶æ•°
        print("   ğŸ” æ‰§è¡Œäº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜ç»„ä»¶æ•°...")
        cv_results = self._cross_validate_components(X_train_scaled, Y_train_scaled)
        
        # 2. è®­ç»ƒæœ€ä¼˜æ¨¡å‹
        best_n_components = cv_results['best_n_components']
        print(f"   âœ… æœ€ä¼˜ä¸»æˆåˆ†æ•°: {best_n_components}")
        
        best_model = PLSRegression(n_components=best_n_components)
        best_model.fit(X_train_scaled, Y_train_scaled)
        
        # 3. éªŒè¯é›†è¯„ä¼°
        val_results = self._evaluate_model(best_model, X_val_scaled, Y_val_scaled, 
                                         X_train_scaled, Y_train_scaled, use_scaling)
        
        # 4. æ¨¡å‹å¤æ‚åº¦åˆ†æ
        complexity_analysis = self._analyze_model_complexity(best_model, X_train_scaled, Y_train_scaled)
        
        # 5. é²æ£’æ€§æµ‹è¯•
        robustness_results = self._test_robustness(best_model, X_val_scaled, Y_val_scaled)
        
        # ä¿å­˜æ¨¡å‹å’Œç»“æœ
        self.models['best_pls'] = best_model
        self.results = {
            'cv_results': cv_results,
            'validation_results': val_results,
            'complexity_analysis': complexity_analysis,
            'robustness_results': robustness_results,
            'best_n_components': best_n_components,
            'use_scaling': use_scaling
        }
        
        self._print_training_summary()
        
        return self.results
    
    def _cross_validate_components(self, X: np.ndarray, Y: np.ndarray) -> Dict:
        """äº¤å‰éªŒè¯é€‰æ‹©æœ€ä¼˜ç»„ä»¶æ•°"""
        
        cv_scores_mean = []
        cv_scores_std = []
        component_range = range(1, min(self.max_components + 1, X.shape[1], X.shape[0]))
        
        # ä½¿ç”¨ç»„äº¤å‰éªŒè¯é¿å…æ•°æ®æ³„éœ²ï¼ˆå¦‚æœæœ‰ç»„ä¿¡æ¯ï¼‰
        kfold = KFold(n_splits=self.cv_folds, shuffle=True, random_state=self.random_state)
        
        for n_comp in component_range:
            pls = PLSRegression(n_components=n_comp)
            
            # å¯¹æ¯ä¸ªç›®æ ‡å˜é‡åˆ†åˆ«è®¡ç®—CVåˆ†æ•°ï¼Œç„¶åå¹³å‡
            cv_scores_per_target = []
            
            for target_idx in range(Y.shape[1]):
                scores = cross_val_score(pls, X, Y[:, target_idx], 
                                       cv=kfold, scoring='r2', n_jobs=-1)
                cv_scores_per_target.append(scores)
            
            # å¹³å‡æ‰€æœ‰ç›®æ ‡å˜é‡çš„åˆ†æ•°
            avg_scores = np.mean(cv_scores_per_target, axis=0)
            cv_scores_mean.append(avg_scores.mean())
            cv_scores_std.append(avg_scores.std())
        
        # é€‰æ‹©æœ€ä¼˜ç»„ä»¶æ•°ï¼ˆè€ƒè™‘æ–¹å·®ï¼‰
        cv_scores_mean = np.array(cv_scores_mean)
        cv_scores_std = np.array(cv_scores_std)
        
        # ä½¿ç”¨1-standard-error ruleé€‰æ‹©æ›´ç®€å•çš„æ¨¡å‹
        best_idx = np.argmax(cv_scores_mean)
        best_score = cv_scores_mean[best_idx]
        best_std = cv_scores_std[best_idx]
        
        # æ‰¾åˆ°åœ¨best_score - best_stdèŒƒå›´å†…çš„æœ€ç®€å•æ¨¡å‹
        threshold = best_score - best_std
        simple_model_idx = np.where(cv_scores_mean >= threshold)[0][0]
        
        best_n_components = component_range[simple_model_idx]
        
        return {
            'component_range': list(component_range),
            'cv_scores_mean': cv_scores_mean.tolist(),
            'cv_scores_std': cv_scores_std.tolist(),
            'best_n_components': best_n_components,
            'best_cv_score': cv_scores_mean[simple_model_idx],
            'best_cv_std': cv_scores_std[simple_model_idx]
        }
    
    def _evaluate_model(self, model, X_val: np.ndarray, Y_val: np.ndarray,
                       X_train: np.ndarray, Y_train: np.ndarray, use_scaling: bool) -> Dict:
        """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        
        # é¢„æµ‹
        Y_train_pred = model.predict(X_train)
        Y_val_pred = model.predict(X_val)
        
        # å¦‚æœä½¿ç”¨äº†ç¼©æ”¾ï¼Œéœ€è¦é€†å˜æ¢
        if use_scaling:
            Y_train_true = self.scaler_Y.inverse_transform(Y_train)
            Y_train_pred = self.scaler_Y.inverse_transform(Y_train_pred)
            Y_val_true = self.scaler_Y.inverse_transform(Y_val)
            Y_val_pred = self.scaler_Y.inverse_transform(Y_val_pred)
        else:
            Y_train_true = Y_train
            Y_val_true = Y_val
        
        # è®¡ç®—å¤šç§è¯„ä¼°æŒ‡æ ‡
        metrics = {}
        
        for dataset_name, y_true, y_pred in [('train', Y_train_true, Y_train_pred), 
                                           ('validation', Y_val_true, Y_val_pred)]:
            
            # æ•´ä½“æŒ‡æ ‡
            metrics[f'{dataset_name}_rmse'] = np.sqrt(mean_squared_error(y_true, y_pred))
            metrics[f'{dataset_name}_mae'] = mean_absolute_error(y_true, y_pred)
            metrics[f'{dataset_name}_r2'] = r2_score(y_true, y_pred)
            
            # æ¯ä¸ªæ°”ä½“çš„æŒ‡æ ‡
            gas_names = ['NO', 'NO2', 'SO2']
            for i, gas in enumerate(gas_names):
                metrics[f'{dataset_name}_{gas}_rmse'] = np.sqrt(mean_squared_error(y_true[:, i], y_pred[:, i]))
                metrics[f'{dataset_name}_{gas}_mae'] = mean_absolute_error(y_true[:, i], y_pred[:, i])
                metrics[f'{dataset_name}_{gas}_r2'] = r2_score(y_true[:, i], y_pred[:, i])
        
        # è®¡ç®—æ³›åŒ–è¯¯å·®
        metrics['generalization_gap_rmse'] = metrics['validation_rmse'] - metrics['train_rmse']
        metrics['generalization_gap_r2'] = metrics['train_r2'] - metrics['validation_r2']
        
        return metrics
    
    def _analyze_model_complexity(self, model, X: np.ndarray, Y: np.ndarray) -> Dict:
        """åˆ†ææ¨¡å‹å¤æ‚åº¦"""
        
        # è·å–PLSç³»æ•°
        coef_matrix = model.coef_  # shape: (n_features, n_targets)
        
        # è®¡ç®—VIP (Variable Importance in Projection) åˆ†æ•°
        vip_scores = self._calculate_vip_scores(model)
        
        # è®¡ç®—å¤æ‚åº¦æŒ‡æ ‡
        complexity = {
            'n_components': model.n_components,
            'n_features': X.shape[1],
            'n_samples': X.shape[0],
            'n_targets': Y.shape[1],
            'coef_sparsity': np.mean(np.abs(coef_matrix) < 1e-6),  # ç³»æ•°ç¨€ç–åº¦
            'coef_l1_norm': np.sum(np.abs(coef_matrix)),
            'coef_l2_norm': np.sqrt(np.sum(coef_matrix ** 2)),
            'effective_rank': np.linalg.matrix_rank(model.x_scores_),  # æœ‰æ•ˆç§©
            'condition_number': np.linalg.cond(model.x_loadings_),  # æ¡ä»¶æ•°
            'vip_scores': vip_scores.tolist(),  # VIPåˆ†æ•°
            'vip_mean': float(vip_scores.mean()),
            'vip_std': float(vip_scores.std()),
            'important_variables_count': int(np.sum(vip_scores > 1.0)),  # VIP>1çš„å˜é‡æ•°
        }
        
        # æ–¹å·®è§£é‡Šæ¯”ä¾‹
        explained_variance = model.x_scores_.var(axis=0)
        total_variance = explained_variance.sum()
        complexity['explained_variance_ratio'] = (explained_variance / total_variance).tolist()
        complexity['cumulative_explained_variance'] = np.cumsum(explained_variance / total_variance).tolist()
        
        return complexity
    
    def _calculate_vip_scores(self, model) -> np.ndarray:
        """
        è®¡ç®—VIP (Variable Importance in Projection) åˆ†æ•°
        
        VIPåˆ†æ•°è¡¡é‡æ¯ä¸ªè¾“å…¥å˜é‡å¯¹PLSæ¨¡å‹çš„é‡è¦æ€§
        VIP > 1.0 é€šå¸¸è¢«è®¤ä¸ºæ˜¯é‡è¦å˜é‡
        
        å…¬å¼: VIP_j = sqrt(p * sum(a_j,h^2 * SS_h) / sum(SS_h))
        å…¶ä¸­:
        - p: å˜é‡æ•°é‡
        - a_j,h: ç¬¬jä¸ªå˜é‡åœ¨ç¬¬hä¸ªä¸»æˆåˆ†ä¸Šçš„loadings
        - SS_h: ç¬¬hä¸ªä¸»æˆåˆ†è§£é‡Šçš„Yæ–¹å·®
        """
        # è·å–Xå’ŒYçš„loadings
        x_loadings = model.x_loadings_  # shape: (n_features, n_components)
        y_loadings = model.y_loadings_  # shape: (n_targets, n_components)
        
        # è®¡ç®—æ¯ä¸ªä¸»æˆåˆ†è§£é‡Šçš„Yæ–¹å·® (SS_h)
        y_scores = model.y_scores_  # shape: (n_samples, n_components)
        ss_components = np.var(y_scores, axis=0, ddof=1)  # æ¯ä¸ªä¸»æˆåˆ†çš„æ–¹å·®
        
        # è®¡ç®—VIPåˆ†æ•°
        n_features = x_loadings.shape[0]
        n_components = x_loadings.shape[1]
        
        # VIPå…¬å¼å®ç°
        vip_scores = np.zeros(n_features)
        total_ss = np.sum(ss_components)
        
        if total_ss > 0:
            for j in range(n_features):
                weighted_loadings_sq = 0
                for h in range(n_components):
                    # æ¯ä¸ªä¸»æˆåˆ†çš„è´¡çŒ® = loadings^2 * è¯¥ä¸»æˆåˆ†è§£é‡Šçš„æ–¹å·®
                    weighted_loadings_sq += (x_loadings[j, h] ** 2) * ss_components[h]
                
                # VIPå…¬å¼
                vip_scores[j] = np.sqrt(n_features * weighted_loadings_sq / total_ss)
        
        return vip_scores
    
    def _test_robustness(self, model, X_val: np.ndarray, Y_val: np.ndarray) -> Dict:
        """é²æ£’æ€§æµ‹è¯•"""
        
        robustness = {}
        
        # 1. å™ªå£°é²æ£’æ€§æµ‹è¯•
        noise_levels = [0.01, 0.05, 0.1, 0.2]
        noise_performance = []
        
        for noise_level in noise_levels:
            # æ·»åŠ å™ªå£°
            X_noisy = X_val + np.random.normal(0, noise_level * X_val.std(), X_val.shape)
            Y_pred_noisy = model.predict(X_noisy)
            
            # è®¡ç®—æ€§èƒ½ä¸‹é™
            r2_noisy = r2_score(Y_val, Y_pred_noisy)
            noise_performance.append(r2_noisy)
        
        robustness['noise_levels'] = noise_levels
        robustness['noise_performance'] = noise_performance
        
        # 2. æ•°æ®åˆ é™¤é²æ£’æ€§ï¼ˆéšæœºåˆ é™¤ä¸€äº›ç‰¹å¾ï¼‰
        feature_removal_ratios = [0.1, 0.2, 0.3]
        removal_performance = []
        
        for removal_ratio in feature_removal_ratios:
            n_remove = int(X_val.shape[1] * removal_ratio)
            np.random.seed(self.random_state)
            remove_indices = np.random.choice(X_val.shape[1], n_remove, replace=False)
            
            X_reduced = np.delete(X_val, remove_indices, axis=1)
            
            # é‡æ–°è®­ç»ƒç®€åŒ–æ¨¡å‹
            model_reduced = PLSRegression(n_components=min(model.n_components, X_reduced.shape[1]))
            # éœ€è¦ç›¸åº”çš„è®­ç»ƒæ•°æ®ï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
            # å®é™…åº”ç”¨ä¸­éœ€è¦ä¼ å…¥å¯¹åº”çš„è®­ç»ƒæ•°æ®
            removal_performance.append(0.0)  # å ä½ç¬¦
        
        robustness['feature_removal_ratios'] = feature_removal_ratios
        robustness['removal_performance'] = removal_performance
        
        return robustness
    
    def _print_training_summary(self):
        """æ‰“å°è®­ç»ƒæ‘˜è¦"""
        results = self.results
        
        print("   âœ… æ¨¡å‹è®­ç»ƒå®Œæˆ!")
        print(f"      ğŸ¯ æœ€ä¼˜ç»„ä»¶æ•°: {results['best_n_components']}")
        print(f"      ğŸ“Š äº¤å‰éªŒè¯RÂ²: {results['cv_results']['best_cv_score']:.5f} Â± {results['cv_results']['best_cv_std']:.5f}")
        
        val_results = results['validation_results']
        print(f"      ğŸš‚ è®­ç»ƒé›† - RMSE: {val_results['train_rmse']:.5f}, RÂ²: {val_results['train_r2']:.5f}")
        print(f"      ğŸ” éªŒè¯é›† - RMSE: {val_results['validation_rmse']:.5f}, RÂ²: {val_results['validation_r2']:.5f}")
        print(f"      ğŸ“ˆ æ³›åŒ–å·®è· - RMSE: {val_results['generalization_gap_rmse']:.5f}, RÂ²: {val_results['generalization_gap_r2']:.5f}")
        
        # æ¯ä¸ªæ°”ä½“çš„æ€§èƒ½
        gas_names = ['NO', 'NO2', 'SO2']
        for gas in gas_names:
            print(f"      {gas}: RÂ² = {val_results[f'validation_{gas}_r2']:.5f}, "
                  f"RMSE = {val_results[f'validation_{gas}_rmse']:.5f}")
    
    def visualize_results(self, X_test: pd.DataFrame, Y_test: pd.DataFrame, 
                         save_dir: str = "data/figures/"):
        """å¯è§†åŒ–æ¨¡å‹ç»“æœ"""
        
        if 'best_pls' not in self.models:
            print("âŒ æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train_with_cross_validation")
            return
        
        os.makedirs(save_dir, exist_ok=True)
        model = self.models['best_pls']
        
        # é¢„æµ‹æµ‹è¯•é›†
        if self.results['use_scaling']:
            X_test_scaled = self.scaler_X.transform(X_test)
            Y_test_pred_scaled = model.predict(X_test_scaled)
            Y_test_pred = self.scaler_Y.inverse_transform(Y_test_pred_scaled)
        else:
            Y_test_pred = model.predict(X_test.values)
        
        # 1. äº¤å‰éªŒè¯æ›²çº¿
        fig, ax = plt.subplots(1, 1, figsize=(10, 6))
        cv_results = self.results['cv_results']
        
        components = cv_results['component_range']
        mean_scores = cv_results['cv_scores_mean']
        std_scores = cv_results['cv_scores_std']
        
        ax.errorbar(components, mean_scores, yerr=std_scores, 
                   marker='o', capsize=5, capthick=2)
        ax.axvline(x=cv_results['best_n_components'], color='red', linestyle='--', 
                  label=f'Optimal: {cv_results["best_n_components"]} components')
        ax.set_xlabel('Number of Components')
        ax.set_ylabel('Cross-Validation RÂ² Score')
        ax.set_title('PLS Cross-Validation Results')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.savefig(f"{save_dir}/cv_component_selection.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 2. é¢„æµ‹ç»“æœå¯¹æ¯”å›¾
        fig, axes = plt.subplots(1, 3, figsize=(18, 5))
        gas_names = ['NO', 'NO2', 'SO2']
        
        for i, gas in enumerate(gas_names):
            y_true = Y_test.values[:, i]
            y_pred = Y_test_pred[:, i]
            
            axes[i].scatter(y_true, y_pred, alpha=0.6, s=50)
            
            # å®Œç¾é¢„æµ‹çº¿
            min_val = min(y_true.min(), y_pred.min())
            max_val = max(y_true.max(), y_pred.max())
            axes[i].plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
            
            # è®¡ç®—RÂ²
            r2 = r2_score(y_true, y_pred)
            rmse = np.sqrt(mean_squared_error(y_true, y_pred))
            
            axes[i].set_xlabel(f'True {gas} Concentration')
            axes[i].set_ylabel(f'Predicted {gas} Concentration')
            axes[i].set_title(f'{gas}: RÂ² = {r2:.4f}, RMSE = {rmse:.4f}')
            axes[i].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{save_dir}/enhanced_prediction_results.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # 3. VIPåˆ†æå¯è§†åŒ–
        self._visualize_vip_analysis(save_dir)
        
        print(f"   ğŸ“Š å¯è§†åŒ–ç»“æœå·²ä¿å­˜åˆ°: {save_dir}")
    
    def _visualize_vip_analysis(self, save_dir: str):
        """å¯è§†åŒ–VIPåˆ†æç»“æœ"""
        
        if 'complexity_analysis' not in self.results:
            return
            
        complexity = self.results['complexity_analysis']
        vip_scores = np.array(complexity['vip_scores'])
        
        # è¯»å–æ³¢æ•°ä¿¡æ¯
        try:
            df = pd.read_csv("data/processed/interpolated_spectra.csv")
            wavenumbers = df['wavenumber'].values
        except:
            wavenumbers = np.arange(len(vip_scores))
        
        # ç¡®ä¿é•¿åº¦åŒ¹é…
        if len(wavenumbers) != len(vip_scores):
            wavenumbers = np.arange(len(vip_scores))
        
        fig, axes = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. VIPåˆ†æ•°åˆ†å¸ƒ
        axes[0, 0].plot(wavenumbers, vip_scores, 'b-', alpha=0.7, linewidth=1)
        axes[0, 0].axhline(y=1.0, color='red', linestyle='--', linewidth=2, 
                          label='VIP = 1.0 (Importance Threshold)')
        axes[0, 0].fill_between(wavenumbers, vip_scores, 1.0, 
                               where=(vip_scores > 1.0), color='red', alpha=0.3,
                               label=f'Important Bands (n={complexity["important_variables_count"]})')
        axes[0, 0].set_xlabel('Wavenumber (cm$^{-1}$)')
        axes[0, 0].set_ylabel('VIP Score')
        axes[0, 0].set_title('Variable Importance in Projection (VIP) Analysis')
        axes[0, 0].legend()
        axes[0, 0].grid(True, alpha=0.3)
        
        # 2. é‡è¦æ³¢æ®µæ”¾å¤§å›¾
        important_indices = np.where(vip_scores > 1.0)[0]
        if len(important_indices) > 0:
            axes[0, 1].stem(wavenumbers[important_indices], vip_scores[important_indices], 
                           basefmt=' ', linefmt='g-', markerfmt='go')
            axes[0, 1].set_xlabel('Wavenumber (cm$^{-1}$)')
            axes[0, 1].set_ylabel('VIP Score')
            axes[0, 1].set_title(f'Important Bands Detail (VIP > 1.0, n={len(important_indices)})')
            axes[0, 1].grid(True, alpha=0.3)
            
            # æ ‡æ³¨æœ€é‡è¦çš„å‰10ä¸ªæ³¢æ®µ
            top_10_indices = important_indices[np.argsort(vip_scores[important_indices])[-10:]]
            for idx in top_10_indices:
                axes[0, 1].annotate(f'{wavenumbers[idx]:.0f}', 
                                   (wavenumbers[idx], vip_scores[idx]),
                                   xytext=(5, 5), textcoords='offset points',
                                   fontsize=8, alpha=0.8)
        else:
            axes[0, 1].text(0.5, 0.5, 'No variables with VIP>1.0', 
                           transform=axes[0, 1].transAxes, ha='center', va='center')
            axes[0, 1].set_title('Important Bands Analysis')
        
        # 3. VIPåˆ†æ•°ç›´æ–¹å›¾
        axes[1, 0].hist(vip_scores, bins=50, alpha=0.7, color='skyblue', edgecolor='black')
        axes[1, 0].axvline(x=1.0, color='red', linestyle='--', linewidth=2, label='VIP = 1.0')
        axes[1, 0].axvline(x=vip_scores.mean(), color='green', linestyle='-', linewidth=2, 
                          label=f'Mean = {vip_scores.mean():.3f}')
        axes[1, 0].set_xlabel('VIP Score')
        axes[1, 0].set_ylabel('Frequency')
        axes[1, 0].set_title('VIP Score Distribution')
        axes[1, 0].legend()
        axes[1, 0].grid(True, alpha=0.3)
        
        # 4. ç´¯ç§¯é‡è¦æ€§åˆ†æ
        sorted_indices = np.argsort(vip_scores)[::-1]  # é™åºæ’åˆ—
        cumulative_importance = np.cumsum(vip_scores[sorted_indices])
        cumulative_percentage = cumulative_importance / cumulative_importance[-1] * 100
        
        axes[1, 1].plot(range(1, len(cumulative_percentage) + 1), cumulative_percentage, 'b-')
        axes[1, 1].axhline(y=80, color='red', linestyle='--', label='80% Importance')
        axes[1, 1].axhline(y=95, color='orange', linestyle='--', label='95% Importance')
        
        # æ‰¾åˆ°è¾¾åˆ°80%å’Œ95%é‡è¦æ€§çš„å˜é‡æ•°
        idx_80 = np.where(cumulative_percentage >= 80)[0]
        idx_95 = np.where(cumulative_percentage >= 95)[0]
        
        if len(idx_80) > 0:
            axes[1, 1].axvline(x=idx_80[0]+1, color='red', linestyle=':', alpha=0.7)
            axes[1, 1].text(idx_80[0]+1, 82, f'{idx_80[0]+1} vars', rotation=90, va='bottom')
            
        if len(idx_95) > 0:
            axes[1, 1].axvline(x=idx_95[0]+1, color='orange', linestyle=':', alpha=0.7)
            axes[1, 1].text(idx_95[0]+1, 97, f'{idx_95[0]+1} vars', rotation=90, va='bottom')
        
        axes[1, 1].set_xlabel('Variable Count (sorted)')
        axes[1, 1].set_ylabel('Cumulative Importance (%)')
        axes[1, 1].set_title('Cumulative Variable Importance')
        axes[1, 1].legend()
        axes[1, 1].grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.savefig(f"{save_dir}/vip_analysis.png", dpi=300, bbox_inches='tight')
        plt.close()
        
        # ä¿å­˜é‡è¦æ³¢æ®µä¿¡æ¯åˆ°CSV
        vip_analysis_df = pd.DataFrame({
            'wavenumber': wavenumbers,
            'vip_score': vip_scores,
            'is_important': vip_scores > 1.0
        })
        vip_analysis_df = vip_analysis_df.sort_values('vip_score', ascending=False)
        vip_analysis_df.to_csv(f"{save_dir}/../results/vip_analysis.csv", index=False)
        
        print(f"   ğŸ¯ VIPåˆ†æå®Œæˆ: {complexity['important_variables_count']} ä¸ªé‡è¦æ³¢æ®µ (VIP > 1.0)")
        print(f"      å¹³å‡VIPåˆ†æ•°: {complexity['vip_mean']:.3f} Â± {complexity['vip_std']:.3f}")
        print(f"      é‡è¦æ³¢æ®µä¿¡æ¯å·²ä¿å­˜åˆ°: {save_dir}/../results/vip_analysis.csv")
    
    def save_model_and_results(self, save_dir: str = "data/models/"):
        """ä¿å­˜æ¨¡å‹å’Œç»“æœ"""
        
        os.makedirs(save_dir, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹
        if 'best_pls' in self.models:
            joblib.dump(self.models['best_pls'], f"{save_dir}/enhanced_pls_model.pkl")
            
            if self.results['use_scaling']:
                joblib.dump(self.scaler_X, f"{save_dir}/scaler_X.pkl")
                joblib.dump(self.scaler_Y, f"{save_dir}/scaler_Y.pkl")
        
        # ä¿å­˜ç»“æœ
        with open(f"{save_dir}/enhanced_training_results.json", 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"   ğŸ’¾ æ¨¡å‹å’Œç»“æœå·²ä¿å­˜åˆ°: {save_dir}")

def main():
    """ä¸»å‡½æ•°ï¼šæ‰§è¡Œå¢å¼ºæ¨¡å‹è®­ç»ƒ"""
    
    # æ£€æŸ¥åˆ†å‰²åçš„æ•°æ®æ˜¯å¦å­˜åœ¨
    required_files = [
        "data/processed/X_train.csv", "data/processed/Y_train.csv",
        "data/processed/X_val.csv", "data/processed/Y_val.csv",
        "data/processed/X_test.csv", "data/processed/Y_test.csv"
    ]
    
    for file_path in required_files:
        if not os.path.exists(file_path):
            print(f"âŒ ç¼ºå°‘æ–‡ä»¶: {file_path}")
            print("   è¯·å…ˆè¿è¡Œ data_splitter.py è¿›è¡Œæ•°æ®åˆ†å‰²")
            return
    
    # åŠ è½½åˆ†å‰²åçš„æ•°æ®
    print("ğŸ“¥ åŠ è½½åˆ†å‰²åçš„æ•°æ®...")
    X_train = pd.read_csv("data/processed/X_train.csv")
    Y_train = pd.read_csv("data/processed/Y_train.csv")
    X_val = pd.read_csv("data/processed/X_val.csv")
    Y_val = pd.read_csv("data/processed/Y_val.csv")
    X_test = pd.read_csv("data/processed/X_test.csv")
    Y_test = pd.read_csv("data/processed/Y_test.csv")
    
    print(f"   è®­ç»ƒé›†: {X_train.shape}, éªŒè¯é›†: {X_val.shape}, æµ‹è¯•é›†: {X_test.shape}")
    
    # åˆ›å»ºå¢å¼ºè®­ç»ƒå™¨
    trainer = EnhancedModelTrainer(max_components=15, cv_folds=5, random_state=42)
    
    # è®­ç»ƒæ¨¡å‹
    results = trainer.train_with_cross_validation(X_train, Y_train, X_val, Y_val, use_scaling=True)
    
    # å¯è§†åŒ–ç»“æœ
    trainer.visualize_results(X_test, Y_test)
    
    # ä¿å­˜æ¨¡å‹å’Œç»“æœ
    trainer.save_model_and_results()
    
    print("ğŸ‰ å¢å¼ºæ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    
    return trainer, results

if __name__ == "__main__":
    main()