# Gas_Three é¡¹ç›®è¯¦ç»†æŠ€æœ¯è¯´æ˜æ–‡æ¡£

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

### ğŸ¯ é¡¹ç›®å®šä½
Gas_Three æ˜¯ä¸€ä¸ªåŸºäº**åæœ€å°äºŒä¹˜æ³•(PLS)å›å½’**çš„æ°”ä½“å…‰è°±åˆ†æç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºé¢„æµ‹**NOã€NO2ã€SO2**ä¸‰ç§æ°”ä½“çš„æµ“åº¦ã€‚è¯¥ç³»ç»Ÿé‡‡ç”¨å…ˆè¿›çš„åŒæ¨¡å‹æ¶æ„ï¼Œç»“åˆäº†å¢å¼ºæ•°æ®é›†å’ŒHITRANæ ‡å‡†æ•°æ®åº“ï¼Œæä¾›é«˜ç²¾åº¦çš„æ°”ä½“æµ“åº¦é¢„æµ‹èƒ½åŠ›ã€‚

### ğŸ”¬ æ ¸å¿ƒæŠ€æœ¯ç‰¹è‰²
- **æ™ºèƒ½æ•°æ®åˆ†å‰²**: åŸºäºæµ“åº¦ç»„åˆçš„åˆ†ç»„ç­–ç•¥ï¼Œå®Œå…¨é¿å…æ•°æ®æ³„éœ²
- **åŒæ¨¡å‹æ¶æ„**: Enhancedæ¨¡å‹ + Standardæ¨¡å‹äº’è¡¥é¢„æµ‹
- **å¤šå±‚æ¬¡å™ªå£°å»ºæ¨¡**: æ¨¡æ‹ŸçœŸå®æµ‹é‡ç¯å¢ƒçš„å¤æ‚å™ªå£°
- **ä¸¥æ ¼äº¤å‰éªŒè¯**: ç¡®ä¿æ¨¡å‹è¯„ä¼°çš„å¯é æ€§å’Œé²æ£’æ€§
- **è‡ªåŠ¨åŒ–æµç¨‹**: ä»æ•°æ®é¢„å¤„ç†åˆ°æ¨¡å‹è®­ç»ƒçš„å…¨è‡ªåŠ¨åŒ–

### ğŸ“Š æ€§èƒ½æŒ‡æ ‡
| æŒ‡æ ‡ | Enhancedæ¨¡å‹ | Standardæ¨¡å‹ |
|------|-------------|-------------|
| **Test RÂ²** | 0.86160 | 0.99122 |
| **Test RMSE** | 0.06311 | 0.01686 |
| **è®­ç»ƒæ ·æœ¬** | 10,545ä¸ª | 3,690ä¸ª |
| **å”¯ä¸€ç»„åˆ** | 703ä¸ª | 369ä¸ª |
| **ä¸»æˆåˆ†æ•°** | 10 | 10 |

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„è¯¦è§£

### ğŸ“ æ ¸å¿ƒç›®å½•ç»“æ„
```
gas_three/
â”œâ”€â”€ ğŸ“‚ æ ¸å¿ƒè®­ç»ƒæµæ°´çº¿
â”‚   â”œâ”€â”€ 01_preprocess.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py      # HITRANæ•°æ®é¢„å¤„ç†
â”‚   â”œâ”€â”€ 02_generate_mixture.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py  # å•ä¸€æ··åˆæ ·æœ¬ç”Ÿæˆ
â”‚   â”œâ”€â”€ 03_generate_dataset.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py  # å¢å¼ºæ•°æ®é›†ç”Ÿæˆ
â”‚   â”œâ”€â”€ 04a_pls_model_default.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py # é»˜è®¤PLSæ¨¡å‹
â”‚   â””â”€â”€ 04b_pls_model_custom.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py  # è‡ªé€‚åº”PLSæ¨¡å‹
â”‚
â”œâ”€â”€ ğŸ”§ ç³»ç»Ÿç®¡ç†å·¥å…·
â”‚   â”œâ”€â”€ how_to_use.py                       # ç³»ç»Ÿä¸»æ§åˆ¶å™¨
â”‚   â”œâ”€â”€ check_status.py                     # ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
â”‚   â”œâ”€â”€ enhanced_model_trainer.py           # å¢å¼ºæ¨¡å‹è®­ç»ƒå™¨
â”‚   â”œâ”€â”€ build_standard_model.py             # æ ‡å‡†æ¨¡å‹æ„å»ºå™¨
â”‚   â”œâ”€â”€ data_splitter.py                    # æ™ºèƒ½æ•°æ®åˆ†å‰²å™¨
â”‚   â””â”€â”€ vip_analyzer.py                     # VIPé‡è¦æ€§åˆ†æ
â”‚
â”œâ”€â”€ ğŸ¯ å¿«é€Ÿä½¿ç”¨å·¥å…·
â”‚   â”œâ”€â”€ how_to_detect.py                    # å¿«é€Ÿæ£€æµ‹å·¥å…·ï¼ˆæ¨èå…¥å£ï¼‰
â”‚   â”œâ”€â”€ detect_spectrum.py                  # å®Œæ•´æ£€æµ‹è„šæœ¬
â”‚   â”œâ”€â”€ predict_real.py                     # Enhancedæ¨¡å‹é¢„æµ‹
â”‚   â”œâ”€â”€ predict_with_standard.py            # Standardæ¨¡å‹é¢„æµ‹
â”‚   â”œâ”€â”€ demo.py                             # åŠŸèƒ½æ¼”ç¤º
â”‚   â””â”€â”€ quick_start_example.py              # å¿«é€Ÿå¼€å§‹ç¤ºä¾‹
â”‚
â”œâ”€â”€ ğŸ§ª æµ‹è¯•ä¸éªŒè¯
â”‚   â””â”€â”€ test/
â”‚       â”œâ”€â”€ test_gas.py                     # æ··åˆå…‰è°±ç”Ÿæˆå™¨
â”‚       â”œâ”€â”€ mixed_spectrum_*.csv            # æµ‹è¯•æ•°æ®
â”‚       â””â”€â”€ mixture_*_visualization.png     # å¯è§†åŒ–ç»“æœ
â”‚
â””â”€â”€ ğŸ“Š æ•°æ®ç®¡ç†
    â””â”€â”€ data/
        â”œâ”€â”€ processed/                      # é¢„å¤„ç†æ•°æ®
        â”œâ”€â”€ raw/                           # åŸå§‹è¾“å…¥æ•°æ®
        â”œâ”€â”€ models/                        # è®­ç»ƒå¥½çš„æ¨¡å‹
        â”œâ”€â”€ results/                       # é¢„æµ‹ç»“æœ
        â””â”€â”€ figures/                       # å¯è§†åŒ–å›¾è¡¨
```

### ğŸ”„ æ•°æ®æµæ¶æ„
```
HITRANåŸå§‹æ•°æ® â†’ é¢„å¤„ç† â†’ æ’å€¼å¯¹é½ â†’ æ··åˆç”Ÿæˆ â†’ å¢å¼ºæ•°æ®é›†
                    â†“
             æ™ºèƒ½æ•°æ®åˆ†å‰² â†’ è®­ç»ƒ/éªŒè¯/æµ‹è¯•é›†
                    â†“
            å¹¶è¡Œæ¨¡å‹è®­ç»ƒ â†’ Enhanced + Standard æ¨¡å‹
                    â†“
              æ¨¡å‹è¯„ä¼° â†’ æ€§èƒ½æŒ‡æ ‡ + VIPåˆ†æ
                    â†“
              å®é™…åº”ç”¨ â†’ å…‰è°±æ£€æµ‹ + æµ“åº¦é¢„æµ‹
```

---

## ğŸ§  æŠ€æœ¯å®ç°åŸç†

### 1. åæœ€å°äºŒä¹˜æ³•(PLS)å›å½’
```python
# æ ¸å¿ƒç®—æ³•å®ç°
from sklearn.cross_decomposition import PLSRegression

model = PLSRegression(n_components=10)
model.fit(X_train_scaled, Y_train_scaled)
```

**æŠ€æœ¯ä¼˜åŠ¿**:
- å¤„ç†é«˜ç»´å…‰è°±æ•°æ®çš„é™ç»´
- åŒæ—¶è€ƒè™‘è¾“å…¥å’Œè¾“å‡ºçš„åæ–¹å·®å…³ç³»
- é€‚åˆæ ·æœ¬æ•°å°äºç‰¹å¾æ•°çš„é—®é¢˜
- å…·æœ‰è‰¯å¥½çš„æ•°å€¼ç¨³å®šæ€§

### 2. æ™ºèƒ½æ•°æ®åˆ†å‰²ç­–ç•¥
```python
# é¿å…æ•°æ®æ³„éœ²çš„æ ¸å¿ƒä»£ç 
Y_copy['combination_id'] = Y_copy.groupby(['NO_conc', 'NO2_conc', 'SO2_conc']).ngroup()

# ç¡®ä¿è®­ç»ƒæµ‹è¯•é›†æµ“åº¦ç»„åˆé›¶é‡å 
unique_combinations = Y_copy['combination_id'].unique()
test_combinations = shuffled[:n_test]
train_combinations = shuffled[n_test+n_val:]
```

**å…³é”®ç‰¹æ€§**:
- åŸºäºæµ“åº¦ç»„åˆçš„åˆ†ç»„åˆ†å‰²
- è®­ç»ƒæµ‹è¯•é›†æµ“åº¦ç»„åˆå®Œå…¨ä¸é‡å 
- é¿å…è¿‡åº¦ä¹è§‚çš„æ€§èƒ½è¯„ä¼°
- ç¡®ä¿æ¨¡å‹æ³›åŒ–èƒ½åŠ›çš„çœŸå®è¯„ä¼°

### 3. å¤šå±‚æ¬¡å™ªå£°å»ºæ¨¡
```python
# å¢å¼ºæ•°æ®é›†çš„å™ªå£°æ¨¡å‹
base_noise = np.random.normal(0, base_noise_level * intensity_scale)
spectral_noise = np.random.normal(0, spectral_noise_level * intensity_scale)
nonlinear_effect = nonlinear_strength * mixed_spectrum * np.random.normal(0, 0.1)

enhanced_spectrum = clean_spectrum + base_noise + spectral_noise + nonlinear_effect
```

**å™ªå£°ç±»å‹**:
- **åŸºç¡€å™ªå£°**: æ¨¡æ‹Ÿä»ªå™¨ç³»ç»Ÿå™ªå£°
- **å…‰è°±å™ªå£°**: æ¨¡æ‹Ÿå…‰è°±ç›¸å…³çš„æµ‹é‡å™ªå£°
- **éçº¿æ€§æ•ˆåº”**: æ¨¡æ‹Ÿæ°”ä½“åˆ†å­é—´ç›¸äº’ä½œç”¨
- **ç³»ç»Ÿåå·®**: æ¨¡æ‹Ÿé•¿æœŸæ¼‚ç§»å’Œç¯å¢ƒå½±å“

### 4. åŒæ¨¡å‹æ¶æ„è®¾è®¡
```python
# Enhanced æ¨¡å‹ï¼šåŸºäºå¤æ‚å¢å¼ºæ•°æ®é›†
enhanced_model = PLSRegression(n_components=10)
enhanced_model.fit(enhanced_X_train, enhanced_Y_train)

# Standard æ¨¡å‹ï¼šåŸºäºHITRANæ ‡å‡†æ•°æ®
standard_model = PLSRegression(n_components=10)
standard_model.fit(standard_X_train, standard_Y_train)

# ç»“æœèåˆ
consensus_result = (enhanced_prediction + standard_prediction) / 2
```

**æ¨¡å‹å¯¹æ¯”**:
- **Enhancedæ¨¡å‹**: æ›´æ¥è¿‘çœŸå®æµ‹é‡æ¡ä»¶ï¼Œæ³›åŒ–èƒ½åŠ›å¼º
- **Standardæ¨¡å‹**: åŸºäºç†è®ºæ•°æ®ï¼Œç²¾åº¦æé«˜ä½†é€‚ç”¨æ€§æœ‰é™
- **èåˆç­–ç•¥**: å–ä¸¤æ¨¡å‹å¹³å‡å€¼ï¼Œå¹³è¡¡ç²¾åº¦å’Œé²æ£’æ€§

---

## ğŸš€ è¯¦ç»†ä½¿ç”¨æŒ‡å—

### ç¬¬ä¸€æ­¥: ç³»ç»Ÿåˆå§‹åŒ–ä¸çŠ¶æ€æ£€æŸ¥
```bash
# 1. è¿›å…¥é¡¹ç›®ç›®å½•
cd E:\generate_mixture\gas_three

# 2. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€ï¼ˆæ¨èé¦–å…ˆæ‰§è¡Œï¼‰
python check_status.py
```

**æœŸæœ›è¾“å‡º**:
```
ENHANCED GAS SPECTROSCOPY SYSTEM STATUS
============================================================
1. CORE FILES STATUS:
   Base spectra: OK
   Enhanced dataset: OK
   Training data: OK
   Enhanced model: OK
   Data scalers: OK

5. SYSTEM STATUS:
   Status: READY
```

### ç¬¬äºŒæ­¥: å¿«é€ŸåŠŸèƒ½éªŒè¯
```bash
# è¿è¡Œæ¼”ç¤ºç¨‹åºéªŒè¯ç³»ç»ŸåŠŸèƒ½
python demo.py

# æˆ–è¿è¡Œå¿«é€Ÿå¼€å§‹ç¤ºä¾‹
python quick_start_example.py
```

### ç¬¬ä¸‰æ­¥: å¤„ç†æ‚¨çš„å®é™…æ•°æ®

#### æ–¹æ³•A: æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼ï¼ˆæ¨èï¼‰
```bash
python how_to_detect.py your_spectrum_file.csv
```

#### æ–¹æ³•B: æ ‡å‡†æ•°æ®è·¯å¾„æ–¹å¼
```bash
# 1. å°†æ‚¨çš„å…‰è°±æ•°æ®é‡å‘½åå¹¶ç§»åŠ¨åˆ°æ ‡å‡†ä½ç½®
cp your_spectrum.csv data/raw/X_real.csv

# 2. è¿è¡Œé¢„æµ‹
python predict_real.py
```

#### æ–¹æ³•C: Pythonä»£ç é›†æˆ
```python
from how_to_detect import quick_detect

# å¿«é€Ÿæ£€æµ‹
result = quick_detect('path/to/your/spectrum.csv')

# ç»“æœæ ¼å¼
print(f"Standard Model: {result['Standard']}")
print(f"Enhanced Model: {result['Enhanced']}")
```

### ç¬¬å››æ­¥: ç³»ç»Ÿç»´æŠ¤ä¸é‡è®­ç»ƒ

#### é‡æ–°è®­ç»ƒEnhancedæ¨¡å‹
```bash
# å®Œæ•´çš„é‡è®­ç»ƒæµç¨‹
python how_to_use.py --retrain

# æˆ–åˆ†æ­¥éª¤æ‰§è¡Œ
python "03_generate_dataset.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py"  # ç”Ÿæˆæ•°æ®
python data_splitter.py                        # æ•°æ®åˆ†å‰²
python enhanced_model_trainer.py               # è®­ç»ƒæ¨¡å‹
```

#### é‡æ–°æ„å»ºStandardæ¨¡å‹
```bash
python build_standard_model.py
```

---

## ğŸ“Š æ•°æ®æ ¼å¼è¯¦ç»†è¯´æ˜

### è¾“å…¥æ•°æ®æ ¼å¼è¦æ±‚
```csv
wavenumber,intensity
587.0,9.643139671328989e-26
588.0,8.733509209604609e-23
589.0,2.2142589032825055e-22
590.0,4.8356789012345678e-22
...
```

**å…³é”®è¦æ±‚**:
- **æ–‡ä»¶æ ¼å¼**: CSVï¼ˆé€—å·åˆ†éš”ï¼‰
- **å¿…é¡»åˆ—**: wavenumberï¼ˆæ³¢æ•°ï¼Œcmâ»Â¹ï¼‰ã€intensityï¼ˆå¼ºåº¦ï¼‰
- **æ•°æ®ç±»å‹**: æ•°å€¼å‹ï¼Œæ”¯æŒç§‘å­¦è®°æ•°æ³•
- **æ³¢æ•°èŒƒå›´**: æ¨èè¦†ç›– 586.7-3690.6 cmâ»Â¹
- **æ•°æ®ç‚¹æ•°**: ç³»ç»Ÿä¼šè‡ªåŠ¨æ’å€¼åˆ°3104ä¸ªæ ‡å‡†æ³¢æ•°ç‚¹
- **æ•°æ®è´¨é‡**: æ— NaNå€¼ï¼Œæ³¢æ•°é€’å¢æ’åˆ—

### è¾“å‡ºç»“æœæ ¼å¼
```csv
Model,NO_concentration,NO_percentage,NO2_concentration,NO2_percentage,SO2_concentration,SO2_percentage
standard,0.2736,27.4,0.3006,30.1,0.4258,42.6
enhanced,0.6669,66.7,0.3331,33.3,0.0,0.0
CONSENSUS,0.4702,47.0,0.3169,31.7,0.2129,21.3
```

**ç»“æœè§£é‡Š**:
- **concentration**: æµ“åº¦å€¼ï¼ˆ0-1ä¹‹é—´ï¼‰
- **percentage**: ç™¾åˆ†æ¯”å½¢å¼ï¼ˆ0-100%ï¼‰
- **CONSENSUS**: ä¸¤ä¸ªæ¨¡å‹çš„å¹³å‡é¢„æµ‹ç»“æœ

---

## ğŸ”§ é«˜çº§é…ç½®ä¸è‡ªå®šä¹‰

### 1. è‡ªå®šä¹‰æ•°æ®ç”Ÿæˆå‚æ•°
ç¼–è¾‘ `03_generate_dataset.pyï¼ˆä¸‰æ°”ä½“ç‰ˆï¼‰.py`ï¼š
```python
# å™ªå£°æ°´å¹³è°ƒæ•´
base_noise_level = 0.08        # åŸºç¡€å™ªå£°ï¼ˆé»˜è®¤8%ï¼‰
spectral_noise_level = 0.05    # å…‰è°±å™ªå£°ï¼ˆé»˜è®¤5%ï¼‰
nonlinear_strength = 0.15      # éçº¿æ€§å¼ºåº¦ï¼ˆé»˜è®¤15%ï¼‰

# æµ“åº¦èŒƒå›´è°ƒæ•´
no_ratios = np.arange(0.05, 0.65, 0.02)   # NOæµ“åº¦èŒƒå›´ï¼š5%-64%
no2_ratios = np.arange(0.05, 0.65, 0.02)  # NO2æµ“åº¦èŒƒå›´ï¼š5%-64%
# SO2æµ“åº¦è‡ªåŠ¨è®¡ç®—ï¼šSO2 = 1 - NO - NO2

# æ•°æ®é›†è§„æ¨¡è°ƒæ•´
augmentation_factor = 15       # æ•°æ®å¢å¼ºå€æ•°
```

### 2. è‡ªå®šä¹‰æ¨¡å‹å‚æ•°
ç¼–è¾‘ç›¸å…³è®­ç»ƒè„šæœ¬ï¼š
```python
# PLSæ¨¡å‹å‚æ•°
model = PLSRegression(
    n_components=10,    # ä¸»æˆåˆ†æ•°ï¼ˆæ¨è5-20ï¼‰
    scale=True,         # æ˜¯å¦æ ‡å‡†åŒ–
    max_iter=500,       # æœ€å¤§è¿­ä»£æ¬¡æ•°
    tol=1e-6           # æ”¶æ•›å®¹å·®
)

# äº¤å‰éªŒè¯å‚æ•°
kfold = KFold(
    n_splits=5,         # æŠ˜æ•°
    shuffle=True,       # æ˜¯å¦æ‰“ä¹±
    random_state=42     # éšæœºç§å­
)
```

### 3. è‡ªå®šä¹‰é¢„å¤„ç†æµç¨‹
```python
# æ³¢æ•°èŒƒå›´è®¾ç½®
wavenumber_min = 586.7    # æœ€å°æ³¢æ•°
wavenumber_max = 3690.6   # æœ€å¤§æ³¢æ•°
wavenumber_step = 1.0     # æ­¥é•¿

# æ’å€¼æ–¹æ³•é€‰æ‹©
interpolation_method = 'linear'  # 'linear', 'cubic', 'quadratic'

# æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•
from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler
scaler = StandardScaler()  # å¯æ›¿æ¢ä¸ºå…¶ä»–æ ‡å‡†åŒ–æ–¹æ³•
```

---

## ğŸ§ª æµ‹è¯•ä¸éªŒè¯æŒ‡å—

### 1. ç”Ÿæˆæµ‹è¯•æ•°æ®
```bash
# è¿›å…¥æµ‹è¯•ç›®å½•
cd test/

# ç”Ÿæˆæ ‡å‡†æ··åˆæ¯”ä¾‹çš„æµ‹è¯•å…‰è°±
python test_gas.py
```

**æµ‹è¯•æ•°æ®ç‰¹æ€§**:
- é»˜è®¤æ··åˆæ¯”ä¾‹ï¼šNO:NO2:SO2 = 2:4:4
- ç”Ÿæˆå¹²å‡€å…‰è°±å’Œå«å™ªå£°å…‰è°±
- è‡ªåŠ¨åˆ›å»ºå¯è§†åŒ–åˆ†æå›¾è¡¨
- åŒ…å«è¯¦ç»†çš„ç»Ÿè®¡ä¿¡æ¯

### 2. æ¨¡å‹æ€§èƒ½è¯„ä¼°
```bash
# è·å–æ¨¡å‹è¯¦ç»†æ€§èƒ½æŒ‡æ ‡
python get_model_performance.py

# VIPé‡è¦æ€§åˆ†æ
python vip_analyzer.py
```

### 3. äº¤å‰éªŒè¯æµ‹è¯•
```python
from sklearn.model_selection import cross_val_score
from sklearn.metrics import make_scorer

# è‡ªå®šä¹‰è¯„ä¼°å‡½æ•°
def custom_r2_score(y_true, y_pred):
    return r2_score(y_true, y_pred)

# æ‰§è¡Œäº¤å‰éªŒè¯
cv_scores = cross_val_score(
    model, X_train_scaled, Y_train_scaled,
    cv=5, scoring=make_scorer(custom_r2_score)
)

print(f"CV RÂ² scores: {cv_scores}")
print(f"Mean CV RÂ²: {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")
```

---

## ğŸ” æ€§èƒ½åˆ†æä¸è§£é‡Š

### 1. Enhancedæ¨¡å‹æ€§èƒ½åˆ†æ
```
è®­ç»ƒé›†æ€§èƒ½:
- RÂ² = 0.91134
- RMSE = 0.05125

æµ‹è¯•é›†æ€§èƒ½:
- RÂ² = 0.86160  
- RMSE = 0.06311

æ³›åŒ–è¯¯å·®: 0.01415 (åˆç†èŒƒå›´å†…)
```

**æ€§èƒ½è§£é‡Š**:
- **RÂ² â‰ˆ 0.86**: æ¨¡å‹è§£é‡Šäº†86%çš„æ–¹å·®ï¼Œæ€§èƒ½è‰¯å¥½ä¸”ç°å®
- **æ³›åŒ–è¯¯å·® < 0.02**: æ¨¡å‹æ²¡æœ‰ä¸¥é‡è¿‡æ‹Ÿåˆ
- **RMSE â‰ˆ 0.06**: å¹³å‡é¢„æµ‹è¯¯å·®çº¦6%ï¼Œåœ¨å·¥ç¨‹åº”ç”¨å¯æ¥å—èŒƒå›´

### 2. Standardæ¨¡å‹æ€§èƒ½åˆ†æ
```
è®­ç»ƒé›†æ€§èƒ½:
- RÂ² â‰ˆ 0.99
- RMSE â‰ˆ 0.015

æµ‹è¯•é›†æ€§èƒ½:
- RÂ² = 0.99122
- RMSE = 0.01686
```

**æ€§èƒ½è§£é‡Š**:
- **RÂ² â‰ˆ 0.99**: æ¥è¿‘å®Œç¾çš„æ‹Ÿåˆï¼Œé€‚ç”¨äºæ ‡å‡†æ°”ä½“
- **RMSE < 0.02**: æä½çš„é¢„æµ‹è¯¯å·®
- **é€‚ç”¨åœºæ™¯**: ç†è®ºè®¡ç®—ã€æ ‡å‡†æ°”ä½“å…‰è°±åˆ†æ

### 3. å•æ°”ä½“æ€§èƒ½åˆ†è§£ï¼ˆEnhancedæ¨¡å‹ï¼‰
```
NO  ç»„åˆ†: RÂ² = 0.87017, RMSE = 0.05633
NO2 ç»„åˆ†: RÂ² = 0.84804, RMSE = 0.06008  
SO2 ç»„åˆ†: RÂ² = 0.86658, RMSE = 0.07189
```

**åˆ†æç»“è®º**:
- ä¸‰ç§æ°”ä½“çš„é¢„æµ‹æ€§èƒ½ç›¸å¯¹å‡è¡¡
- SO2çš„RMSEç•¥é«˜ï¼Œå¯èƒ½ç”±äºå…‰è°±å¤æ‚åº¦è¾ƒé«˜
- æ•´ä½“æ€§èƒ½æ»¡è¶³å®é™…åº”ç”¨éœ€æ±‚

---

## ğŸ› ï¸ æ•…éšœæ’é™¤æŒ‡å—

### å¸¸è§é—®é¢˜1: æ¨¡å‹æ–‡ä»¶æœªæ‰¾åˆ°
**é”™è¯¯ä¿¡æ¯**: `FileNotFoundError: [Errno 2] No such file or directory: 'data/models/enhanced_pls_model.pkl'`

**è§£å†³æ–¹æ¡ˆ**:
```bash
# 1. æ£€æŸ¥ç³»ç»ŸçŠ¶æ€
python check_status.py

# 2. å¦‚æœæ˜¾ç¤ºNOT READYï¼Œè¿è¡Œç³»ç»Ÿè®¾ç½®
python how_to_use.py

# 3. å¦‚æœé—®é¢˜æŒç»­ï¼Œé‡æ–°è®­ç»ƒæ¨¡å‹
python how_to_use.py --retrain
```

### å¸¸è§é—®é¢˜2: ç‰¹å¾ç»´åº¦ä¸åŒ¹é…
**é”™è¯¯ä¿¡æ¯**: `ValueError: X has n features, but StandardScaler is expecting m features`

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ç»´åº¦é—®é¢˜ï¼Œä½†å¦‚æœä»æœ‰é—®é¢˜ï¼š

# æ£€æŸ¥è¾“å…¥æ•°æ®ç»´åº¦
import pandas as pd
df = pd.read_csv('your_file.csv')
print(f"æ•°æ®ç»´åº¦: {df.shape}")
print(f"åˆ—å: {list(df.columns)}")

# ç¡®ä¿æ•°æ®æ ¼å¼æ­£ç¡®
if len(df.columns) < 2:
    print("é”™è¯¯ï¼šæ•°æ®æ–‡ä»¶éœ€è¦è‡³å°‘ä¸¤åˆ—ï¼ˆæ³¢æ•°å’Œå¼ºåº¦ï¼‰")
```

### å¸¸è§é—®é¢˜3: æ•°æ®æ ¼å¼é”™è¯¯
**é”™è¯¯ä¿¡æ¯**: `KeyError: 'wavenumber'` æˆ– `KeyError: 'intensity'`

**è§£å†³æ–¹æ¡ˆ**:
```python
# æ£€æŸ¥CSVæ–‡ä»¶æ ¼å¼
df = pd.read_csv('your_file.csv')

# æ–¹æ³•1ï¼šé‡å‘½ååˆ—
if 'frequency' in df.columns:
    df.rename(columns={'frequency': 'wavenumber'}, inplace=True)
if 'absorbance' in df.columns:
    df.rename(columns={'absorbance': 'intensity'}, inplace=True)

# æ–¹æ³•2ï¼šä½¿ç”¨ä½ç½®ç´¢å¼•
# ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨å‰ä¸¤åˆ—ä½œä¸ºæ³¢æ•°å’Œå¼ºåº¦
```

### å¸¸è§é—®é¢˜4: é¢„æµ‹ç»“æœå¼‚å¸¸
**é—®é¢˜æè¿°**: é¢„æµ‹æµ“åº¦ä¸ºè´Ÿå€¼æˆ–æ€»å’Œä¸ä¸º1

**è§£å†³æ–¹æ¡ˆ**:
```python
# ç³»ç»Ÿå†…ç½®äº†ç»“æœåå¤„ç†æœºåˆ¶
Y_pred = np.maximum(Y_pred, 0)  # ç¡®ä¿éè´Ÿ
Y_pred = Y_pred / Y_pred.sum(axis=1, keepdims=True)  # å½’ä¸€åŒ–

# å¦‚æœé—®é¢˜æŒç»­ï¼Œæ£€æŸ¥è¾“å…¥æ•°æ®è´¨é‡ï¼š
# 1. æ³¢æ•°èŒƒå›´æ˜¯å¦åˆç†
# 2. å¼ºåº¦æ•°å€¼æ˜¯å¦åœ¨æ­£å¸¸èŒƒå›´
# 3. æ˜¯å¦åŒ…å«å¼‚å¸¸å€¼æˆ–NaN
```

### å¸¸è§é—®é¢˜5: ç³»ç»Ÿè¿è¡Œç¼“æ…¢
**ä¼˜åŒ–å»ºè®®**:
```python
# 1. å‡å°‘æ•°æ®é›†è§„æ¨¡ï¼ˆç”¨äºå¿«é€Ÿæµ‹è¯•ï¼‰
# åœ¨ 03_generate_dataset.py ä¸­è°ƒæ•´ï¼š
augmentation_factor = 5  # ä»15å‡å°‘åˆ°5

# 2. å‡å°‘äº¤å‰éªŒè¯æŠ˜æ•°
cv_folds = 3  # ä»5å‡å°‘åˆ°3

# 3. ä½¿ç”¨æ›´å°‘çš„ä¸»æˆåˆ†
n_components = 5  # ä»10å‡å°‘åˆ°5
```

---

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ•°æ®è´¨é‡ä¼˜åŒ–
```python
# æ•°æ®æ¸…æ´—å’Œè´¨é‡æ§åˆ¶
def optimize_data_quality(df):
    # ç§»é™¤å¼‚å¸¸å€¼
    Q1 = df['intensity'].quantile(0.25)
    Q3 = df['intensity'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound = Q1 - 1.5 * IQR
    upper_bound = Q3 + 1.5 * IQR
    
    df_clean = df[(df['intensity'] >= lower_bound) & 
                  (df['intensity'] <= upper_bound)]
    
    # å¹³æ»‘å¤„ç†
    from scipy.signal import savgol_filter
    df_clean['intensity_smooth'] = savgol_filter(
        df_clean['intensity'], window_length=5, polyorder=2
    )
    
    return df_clean
```

### 2. æ¨¡å‹è¶…å‚æ•°ä¼˜åŒ–
```python
from sklearn.model_selection import GridSearchCV

# ç½‘æ ¼æœç´¢æœ€ä¼˜å‚æ•°
param_grid = {
    'n_components': [5, 8, 10, 12, 15],
    'max_iter': [300, 500, 1000]
}

grid_search = GridSearchCV(
    PLSRegression(), param_grid, 
    cv=5, scoring='r2', n_jobs=-1
)

grid_search.fit(X_train_scaled, Y_train_scaled)
best_params = grid_search.best_params_
```

### 3. é›†æˆå­¦ä¹ ç­–ç•¥
```python
# å¤šæ¨¡å‹é›†æˆ
from sklearn.ensemble import VotingRegressor

# åˆ›å»ºå¤šä¸ªPLSæ¨¡å‹
pls1 = PLSRegression(n_components=8)
pls2 = PLSRegression(n_components=10)  
pls3 = PLSRegression(n_components=12)

# é›†æˆæŠ•ç¥¨
ensemble = VotingRegressor([
    ('pls1', pls1),
    ('pls2', pls2), 
    ('pls3', pls3)
])

ensemble.fit(X_train_scaled, Y_train_scaled)
```

---

## ğŸ¯ æœ€ä½³å®è·µå»ºè®®

### 1. æ•°æ®æ”¶é›†æœ€ä½³å®è·µ
- **å…‰è°±è´¨é‡**: ç¡®ä¿ä¿¡å™ªæ¯” > 100:1
- **æ³¢æ•°èŒƒå›´**: å°½å¯èƒ½è¦†ç›–å®Œæ•´çš„ç‰¹å¾åŒºåŸŸ
- **é‡‡æ ·å¯†åº¦**: æ¨è â‰¤ 1 cmâ»Â¹ é—´éš”
- **åŸºçº¿æ ¡æ­£**: é¢„å…ˆè¿›è¡ŒåŸºçº¿æ ¡æ­£å’ŒèƒŒæ™¯æ‰£é™¤
- **ç¯å¢ƒæ§åˆ¶**: ä¿æŒæµ‹é‡ç¯å¢ƒçš„ä¸€è‡´æ€§

### 2. æ¨¡å‹è®­ç»ƒæœ€ä½³å®è·µ
- **æ•°æ®åˆ†å‰²**: å§‹ç»ˆä½¿ç”¨åŸºäºæµ“åº¦ç»„åˆçš„åˆ†å‰²ç­–ç•¥
- **äº¤å‰éªŒè¯**: ä½¿ç”¨è‡³å°‘5æŠ˜äº¤å‰éªŒè¯
- **è¶…å‚æ•°é€‰æ‹©**: é€šè¿‡ç½‘æ ¼æœç´¢ä¼˜åŒ–ä¸»æˆåˆ†æ•°
- **æ¨¡å‹è¯„ä¼°**: ä½¿ç”¨å¤šç§æŒ‡æ ‡ï¼ˆRÂ²ã€RMSEã€MAEï¼‰ç»¼åˆè¯„ä¼°
- **é²æ£’æ€§æµ‹è¯•**: åœ¨ä¸åŒå™ªå£°æ°´å¹³ä¸‹æµ‹è¯•æ¨¡å‹æ€§èƒ½

### 3. ç³»ç»Ÿéƒ¨ç½²æœ€ä½³å®è·µ
- **å®šæœŸæ ¡å‡†**: å»ºè®®æ¯æœˆè¿è¡Œä¸€æ¬¡ç³»ç»ŸçŠ¶æ€æ£€æŸ¥
- **æ¨¡å‹æ›´æ–°**: å½“æœ‰æ–°çš„æ ‡å‡†æ•°æ®æ—¶é‡æ–°è®­ç»ƒæ¨¡å‹
- **ç»“æœéªŒè¯**: ä½¿ç”¨å·²çŸ¥æ ·å“å®šæœŸéªŒè¯é¢„æµ‹å‡†ç¡®æ€§
- **å¤‡ä»½ç­–ç•¥**: å®šæœŸå¤‡ä»½æ¨¡å‹æ–‡ä»¶å’Œé‡è¦æ•°æ®
- **æ—¥å¿—è®°å½•**: è®°å½•æ‰€æœ‰é¢„æµ‹ç»“æœå’Œç³»ç»ŸçŠ¶æ€

---

## ğŸ“ æŠ€æœ¯æ”¯æŒä¸æ‰©å±•

### è·å–å¸®åŠ©
1. **ç³»ç»Ÿè¯Šæ–­**: `python check_status.py`
2. **åŠŸèƒ½æ¼”ç¤º**: `python demo.py`
3. **å¿«é€Ÿæµ‹è¯•**: `python quick_start_example.py`
4. **å®Œæ•´é‡å»º**: `python how_to_use.py --retrain`

### æ‰©å±•å¼€å‘
è¯¥ç³»ç»Ÿå…·æœ‰è‰¯å¥½çš„å¯æ‰©å±•æ€§ï¼Œæ”¯æŒä»¥ä¸‹æ‰©å±•ï¼š

1. **å¢åŠ æ°”ä½“ç§ç±»**: ä¿®æ”¹æ ¸å¿ƒå¤„ç†æ–‡ä»¶æ”¯æŒæ›´å¤šæ°”ä½“
2. **ä¸åŒç®—æ³•**: æ›¿æ¢PLSä¸ºå…¶ä»–å›å½’ç®—æ³•ï¼ˆSVRã€Random Forestç­‰ï¼‰
3. **å®æ—¶é¢„æµ‹**: é›†æˆåˆ°å®æ—¶ç›‘æµ‹ç³»ç»Ÿ
4. **GUIç•Œé¢**: å¼€å‘å›¾å½¢ç”¨æˆ·ç•Œé¢
5. **APIæœåŠ¡**: æ„å»ºRESTful APIæœåŠ¡

### å¼•ç”¨ä¿¡æ¯
å¦‚æœæ‚¨åœ¨ç§‘ç ”å·¥ä½œä¸­ä½¿ç”¨äº†æœ¬ç³»ç»Ÿï¼Œè¯·å¼•ç”¨ï¼š
- **ç®—æ³•**: Partial Least Squares (PLS) Regression
- **æ•°æ®æº**: HITRAN Database
- **å®ç°**: scikit-learn PLSRegression
- **æ¶æ„**: Enhanced + Standard åŒæ¨¡å‹ç³»ç»Ÿ

---

*æ–‡æ¡£ç‰ˆæœ¬: v1.0 | æœ€åæ›´æ–°: 2025å¹´1æœˆ | é¡¹ç›®è·¯å¾„: E:\generate_mixture\gas_three\*